{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pdkang/multi-agent/blob/main/01_Agentic_RAG_Notebook_pk.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Deep Dive Agentic Retrieval Augmented Generation\n",
        "\n",
        "An Agentic RAG is required when we use reasoning to determine which action(s) to take and in which order to take them. Essentially we use agents instead of a LLM directly to accomplish a set of tasks which requires planning, multi step reasoning, tool use and/or learning over time. Agents give us agency!\n",
        "\n",
        "Agency : The ability to take action or to choose what action to take\n",
        "\n",
        "In the context of RAG, we can plug in agents to enhance the reasoning prior to selection of RAG pipelines, within a RAG pipeline for retrieval or reranking and finally for synthesising before we send out the response. This improves RAG to a large extent by automating complex workflows and decisions that are required for a non trivial RAG use case.\n",
        "\n",
        "### Purpose of this Agentic RAG\n",
        "This notebook presents a practical implementation of Agentic Retrieval-Augmented Generation (RAG)‚Äîa system where decision-making and tool selection are delegated to an intelligent agent before executing a response. Rather than passing every query through a static RAG pipeline, this system introduces agency‚Äîthe ability to choose the best course of action depending on the nature of the query.\n",
        "\n",
        "At the heart of this implementation is a router prompt, which classifies user queries into one of three categories:\n",
        "\n",
        "- OpenAI documentation: Queries related to tools, APIs, or usage guidelines for OpenAI models\n",
        "- 10-K financial reports: Questions requiring retrieval from company filings or financial datasets\n",
        "- Live Internet search: Broader, current, or comparative queries that need web access\n",
        "\n",
        "Once the query is classified, the system invokes a corresponding route handler:\n",
        "\n",
        "- For OpenAI and 10-K queries, it retrieves relevant context from a vector database (Qdrant) using text embeddings, then applies a RAG-based response generator.\n",
        "- For Internet queries, it fetches real-time information using a web-access API (ARES).\n",
        "\n",
        "This approach is an example of Agentic RAG, where reasoning precedes retrieval and generation. By plugging in agents before and within the RAG pipeline, we make the system smarter and more adaptive. This allows us to:\n",
        "\n",
        "- Automatically choose the right retrieval method based on context\n",
        "- Combine structured knowledge with real-time search\n",
        "- Scale RAG beyond trivial use cases by integrating multi-step decision logic\n",
        "\n",
        "Importantly, no external agentic frameworks are used‚Äîthis is a ground-up implementation that demonstrates how to build a lightweight but intelligent agentic system using only a language model, prompt engineering, and retrieval tools."
      ],
      "metadata": {
        "id": "mJ9XHTOPUCav"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setup and Dependencies"
      ],
      "metadata": {
        "id": "haelye0PUbdX"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "HciDI6OpSKJN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "812cd487-3a51-4da7-9c10-b666d37cb97d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openai in /usr/local/lib/python3.11/dist-packages (1.76.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai) (4.9.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.9.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from openai) (2.11.3)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.11/dist-packages (from openai) (4.13.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (2025.4.26)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.1 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (2.33.1)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (0.4.0)\n",
            "Collecting qdrant_client\n",
            "  Downloading qdrant_client-1.14.2-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: grpcio>=1.41.0 in /usr/local/lib/python3.11/dist-packages (from qdrant_client) (1.71.0)\n",
            "Requirement already satisfied: httpx>=0.20.0 in /usr/local/lib/python3.11/dist-packages (from httpx[http2]>=0.20.0->qdrant_client) (0.28.1)\n",
            "Requirement already satisfied: numpy>=1.21 in /usr/local/lib/python3.11/dist-packages (from qdrant_client) (2.0.2)\n",
            "Collecting portalocker<3.0.0,>=2.7.0 (from qdrant_client)\n",
            "  Downloading portalocker-2.10.1-py3-none-any.whl.metadata (8.5 kB)\n",
            "Requirement already satisfied: protobuf>=3.20.0 in /usr/local/lib/python3.11/dist-packages (from qdrant_client) (5.29.4)\n",
            "Requirement already satisfied: pydantic!=2.0.*,!=2.1.*,!=2.2.0,>=1.10.8 in /usr/local/lib/python3.11/dist-packages (from qdrant_client) (2.11.3)\n",
            "Requirement already satisfied: urllib3<3,>=1.26.14 in /usr/local/lib/python3.11/dist-packages (from qdrant_client) (2.4.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx>=0.20.0->httpx[http2]>=0.20.0->qdrant_client) (4.9.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.20.0->httpx[http2]>=0.20.0->qdrant_client) (2025.4.26)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.20.0->httpx[http2]>=0.20.0->qdrant_client) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx>=0.20.0->httpx[http2]>=0.20.0->qdrant_client) (3.10)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.20.0->httpx[http2]>=0.20.0->qdrant_client) (0.16.0)\n",
            "Requirement already satisfied: h2<5,>=3 in /usr/local/lib/python3.11/dist-packages (from httpx[http2]>=0.20.0->qdrant_client) (4.2.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=2.0.*,!=2.1.*,!=2.2.0,>=1.10.8->qdrant_client) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.1 in /usr/local/lib/python3.11/dist-packages (from pydantic!=2.0.*,!=2.1.*,!=2.2.0,>=1.10.8->qdrant_client) (2.33.1)\n",
            "Requirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.11/dist-packages (from pydantic!=2.0.*,!=2.1.*,!=2.2.0,>=1.10.8->qdrant_client) (4.13.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=2.0.*,!=2.1.*,!=2.2.0,>=1.10.8->qdrant_client) (0.4.0)\n",
            "Requirement already satisfied: hyperframe<7,>=6.1 in /usr/local/lib/python3.11/dist-packages (from h2<5,>=3->httpx[http2]>=0.20.0->qdrant_client) (6.1.0)\n",
            "Requirement already satisfied: hpack<5,>=4.1 in /usr/local/lib/python3.11/dist-packages (from h2<5,>=3->httpx[http2]>=0.20.0->qdrant_client) (4.1.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx>=0.20.0->httpx[http2]>=0.20.0->qdrant_client) (1.3.1)\n",
            "Downloading qdrant_client-1.14.2-py3-none-any.whl (327 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m327.7/327.7 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading portalocker-2.10.1-py3-none-any.whl (18 kB)\n",
            "Installing collected packages: portalocker, qdrant_client\n",
            "Successfully installed portalocker-2.10.1 qdrant_client-1.14.2\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.51.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.30.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2025.3.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.13.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.4.26)\n"
          ]
        }
      ],
      "source": [
        "# Install the necessary libraries\n",
        "!pip install openai\n",
        "!pip install qdrant_client\n",
        "!pip install transformers\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import basic libraries\n",
        "import requests             # Used for making HTTP requests (e.g., calling ARES API for live internet queries)\n",
        "import json                 # For parsing and structuring JSON data (especially OpenAI and routing responses)\n",
        "\n",
        "# Google Colab-specific (for securely handling API keys)\n",
        "from google.colab import userdata  # To securely store and retrieve credentials in Colab\n",
        "\n",
        "# OS operations\n",
        "import os                   # Useful for accessing environment variables and managing paths\n",
        "\n",
        "# OpenAI API client\n",
        "from openai import OpenAI   # Official OpenAI client library to interface with GPT models for routing and generation\n",
        "\n",
        "# Text processing\n",
        "import re                   # Regular expressions for cleaning or preprocessing inputs (if needed)\n",
        "\n",
        "# Optional visualization (for analysis/debugging purposes)\n",
        "import matplotlib.pyplot as plt       # For displaying charts or visual debug outputs (e.g., embeddings visualizations)\n",
        "import matplotlib.image as mpimg      # For loading/displaying images if needed (rare in RAG, but helpful in demos)\n",
        "\n",
        "# Embedding models (used for text vectorization during retrieval)\n",
        "from transformers import AutoTokenizer, AutoModel  # For loading custom transformer models if not using OpenAI embeddings\n",
        "\n",
        "# Vector database client\n",
        "from qdrant_client import QdrantClient   # Qdrant is used as the vector store to retrieve documents based on similarity\n"
      ],
      "metadata": {
        "id": "J7xIyE7iyI63"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Defining the Internet Tool\n",
        "\n",
        "First, we will define a tool function that enables our system to answer queries requiring real-time, internet-based information. Not all questions can be answered using static documents like OpenAI docs or financial filings‚Äîsometimes users ask about current trends, comparisons, or live updates.\n",
        "\n",
        "To handle this, we introduce a live search capability using the **ARES API** by Traversaal.\n",
        "\n",
        "### What is ARES API?  \n",
        "ARES is a web-based tool that allows you to:\n",
        "\n",
        "- Search the internet in real time.\n",
        "- Get LLM-generated answers based on live search results.\n",
        "\n",
        "This is particularly useful for questions about:\n",
        "\n",
        "- Current events (e.g., *‚ÄúLatest AI tools in 2025‚Äù*),\n",
        "- Tech comparisons (e.g., *‚ÄúGemini vs GPT-4‚Äù*),\n",
        "- General knowledge outside internal datasets.\n",
        "\n",
        "Please generate the API key [here](https://api.traversaal.ai)\n"
      ],
      "metadata": {
        "id": "JE6Bf6r19qhn"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1PydVhqpW43B"
      },
      "outputs": [],
      "source": [
        "#loads ares api key from colab secrets\n",
        "ares_api_key=userdata.get('ARES_API_KEY')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6tF67DJgZ_sz"
      },
      "outputs": [],
      "source": [
        "import requests  # For sending HTTP POST requests to the ARES API\n",
        "\n",
        "def get_internet_content(user_query: str, action: str):\n",
        "    \"\"\"\n",
        "    Fetches a response from the internet using ARES-API based on the user's query.\n",
        "\n",
        "    This function serves as the tool invoked when the router classifies a query\n",
        "    as requiring real-time information beyond internal datasets‚Äîi.e., \"INTERNET_QUERY\".\n",
        "    It sends the query to a live search API (ARES) and returns the result.\n",
        "\n",
        "    Args:\n",
        "        user_query (str): The user's question that needs a live answer.\n",
        "        action (str): Route type (always expected to be \"INTERNET_QUERY\").\n",
        "\n",
        "    Returns:\n",
        "        str: Response text generated using internet search or an error message.\n",
        "    \"\"\"\n",
        "    print(\"Getting your response from the internet üåê ...\")\n",
        "\n",
        "    # API endpoint for the ARES live search tool\n",
        "    url = \"https://api-ares.traversaal.ai/live/predict\"\n",
        "\n",
        "    # Payload structure expected by the ARES API\n",
        "    payload = {\"query\": [user_query]}\n",
        "\n",
        "    # Authentication and content headers for API access\n",
        "    headers = {\n",
        "        \"x-api-key\": ares_api_key,  # Your secret API key (should be securely loaded from environment)\n",
        "        \"content-type\": \"application/json\"\n",
        "    }\n",
        "\n",
        "    try:\n",
        "        # Send the query to the ARES API and check for success\n",
        "        response = requests.post(url, json=payload, headers=headers)\n",
        "        response.raise_for_status()\n",
        "\n",
        "        # Extract and return the main response text from the API's nested JSON\n",
        "        return response.json().get('data', {}).get('response_text', \"No response received.\")\n",
        "\n",
        "    # Handle HTTP-level errors (e.g., 400s or 500s)\n",
        "    except requests.exceptions.HTTPError as http_err:\n",
        "        return f\"HTTP error occurred: {http_err}\"\n",
        "\n",
        "    # Handle general connection, timeout, or request formatting issues\n",
        "    except requests.exceptions.RequestException as req_err:\n",
        "        return f\"Request error occurred: {req_err}\"\n",
        "\n",
        "    # Catch-all for any unexpected failure\n",
        "    except Exception as err:\n",
        "        return f\"An unexpected error occurred: {err}\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "USRVlUIVaRGM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "63c25fd5-df22-4db0-fbb4-fae9abfa2c50"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Getting your response from the internet üåê ...\n",
            "Here are some of the best travel destinations for 2025:\n",
            "\n",
            "1. **Budapest, Hungary** - Known for its stunning architecture and rich history, Budapest offers a vibrant cultural experience.\n",
            "2. **Bukhara, Uzbekistan** - A city steeped in history, Bukhara is famous for its well-preserved medieval architecture.\n",
            "3. **Charleston, South Carolina, USA** - Renowned for its historic charm, beautiful beaches, and Southern hospitality.\n",
            "4. **Inverness and the Flow Country, Scotland** - A picturesque area known for its natural beauty and proximity to Loch Ness.\n",
            "5. **Seoul, South Korea** - A bustling metropolis that blends modernity with tradition, offering a unique cultural experience.\n",
            "6. **Kathmandu, Nepal** - The gateway to the Himalayas, known for its rich culture and history.\n",
            "7. **Cusco, Peru** - The historic capital of the Inca Empire, offering access to Machu Picchu and rich cultural experiences.\n",
            "8. **Bangkok, Thailand** - A vibrant city known for its street life, cultural landmarks, and delicious cuisine.\n",
            "9. **Osaka, Japan** - Famous for its modern architecture, nightlife, and hearty street food.\n",
            "10. **Dubai, UAE** - Known for luxury shopping, ultramodern architecture, and a lively nightlife scene.\n",
            "11. **Mauritius** - An island nation known for its stunning beaches, lagoons, and diverse culture.\n",
            "12. **Bali, Indonesia** - A popular destination for its beautiful beaches, vibrant culture, and wellness retreats.\n",
            "13. **Maldives** - Renowned for its crystal-clear waters and luxurious overwater bungalows.\n",
            "14. **Hoi An, Vietnam** - A well-preserved ancient town known for its historic architecture and vibrant markets.\n",
            "15. **Phuket, Thailand** - Famous for its beautiful beaches and vibrant nightlife.\n",
            "16. **Santorini, Greece** - Known for its stunning sunsets, whitewashed buildings, and beautiful beaches.\n",
            "17. **Zanzibar, Tanzania** - An island known for its beautiful beaches, rich history, and spice plantations.\n",
            "18. **Dominica** - Known for its natural hot springs, lush rainforests, and beautiful hiking trails.\n",
            "19. **Naoshima, Japan** - An island famous for its contemporary art museums and installations.\n",
            "20. **The Dolomites, Italy** - A mountain range known for its stunning scenery and outdoor activities.\n",
            "21. **Greenland** - Offers breathtaking landscapes and unique cultural experiences.\n",
            "22. **Wales** - Known for its rugged coastline, mountainous national parks, and rich history.\n",
            "\n",
            "These destinations are highlighted for their unique offerings, cultural experiences, and natural beauty, making them ideal for travelers in 2025.\n"
          ]
        }
      ],
      "source": [
        "print(get_internet_content(\"what are the best travel destinitions of 2025\",\"INTERNET_QUERY\")) #run internet function to test results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ocV_ALVEaRi0"
      },
      "source": [
        "## 2. Router Query Function ‚Äî Giving the Agent Its Brain\n",
        "\n",
        "In this step, we will define the router function, which plays a critical role in our Agentic RAG system.\n",
        "\n",
        "### What is a Router?\n",
        "\n",
        "A router is like the decision-making brain of our assistant.\n",
        "\n",
        "Before trying to answer a user's question, the system first needs to figure out:\n",
        "\n",
        "> ‚ÄúWhere should I go to find the right answer?‚Äù\n",
        "\n",
        "To make this decision, we use the OpenAI GPT model. We provide it with a detailed system prompt that explains how to classify the user's question into one of these categories:\n",
        "\n",
        "- **OPENAI_QUERY** ‚Üí Questions about OpenAI tools, APIs, models, or documentation.\n",
        "- **10K_DOCUMENT_QUERY** ‚Üí Questions about companies, financial filings, or analysis based on 10-K reports.\n",
        "- **INTERNET_QUERY** ‚Üí Anything else that likely requires real-time or general web information.\n",
        "\n",
        "### What does the function do?\n",
        "\n",
        "- Sends the user's question to the OpenAI API.\n",
        "- Receives a JSON response containing:\n",
        "  - `action`: The category the query belongs to.\n",
        "  - `reason`: A short explanation for the decision.\n",
        "  - `answer`: (Optional) A quick response if it‚Äôs simple enough (left blank for internet queries).\n",
        "- Parses the response and returns it as a Python dictionary.\n",
        "\n",
        "### Why is this important?\n",
        "\n",
        "This router gives the system agency‚Äîthe ability to decide which knowledge source to use. It‚Äôs what makes this pipeline agentic, not just static.\n",
        "\n",
        "Without the router, every query would follow the same path. With it, we can:\n",
        "\n",
        "- Dynamically switch between tools and data sources.\n",
        "- Handle different types of user questions intelligently.\n",
        "- Avoid wasting resources on unnecessary steps.\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Securely retrieve the OpenAI API key from Colab's user data store\n",
        "# This avoids hardcoding sensitive credentials directly in the notebook\n",
        "openai_api_key = userdata.get('OPENAI_API_KEY')\n",
        "\n",
        "# Initialize the OpenAI client with the retrieved API key\n",
        "# This client will be used for:\n",
        "# - Query classification via the router prompt\n",
        "# - Potentially generating responses from retrieved context\n",
        "openaiclient = OpenAI(api_key=openai_api_key)\n"
      ],
      "metadata": {
        "id": "Bce4h1DG1mW8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H47ZuaYiSYxQ"
      },
      "outputs": [],
      "source": [
        "from openai import OpenAIError\n",
        "\n",
        "def route_query(user_query: str):\n",
        "    \"\"\"\n",
        "    Routes a user query to the appropriate source (OpenAI, 10k, or Internet).\n",
        "\n",
        "    This function acts as the 'brain' of the agentic RAG system. It uses an LLM (GPT-4)\n",
        "    to reason about the nature of the user's query and classify it into one of three routes:\n",
        "\n",
        "    - \"OPENAI_QUERY\": For queries about OpenAI tools, models, or documentation\n",
        "    - \"10K_DOCUMENT_QUERY\": For finance-related questions requiring 10-K filings\n",
        "    - \"INTERNET_QUERY\": For open-ended, trending, or external-topic queries\n",
        "\n",
        "    The LLM returns a structured JSON with:\n",
        "    - action: selected route\n",
        "    - reason: rationale behind routing decision\n",
        "    - answer: a short answer (if applicable)\n",
        "\n",
        "    Returns:\n",
        "        dict: Classification output containing route, reasoning, and (optional) short answer.\n",
        "    \"\"\"\n",
        "\n",
        "    # Construct a system prompt that instructs the model to act as a strict query router.\n",
        "    # It explains the criteria for each classification and enforces a fixed response format.\n",
        "    router_system_prompt =f\"\"\"\n",
        "    As a professional query router, your objective is to correctly classify user input into one of three categories based on the source most relevant for answering the query:\n",
        "\n",
        "    1. \"OPENAI_QUERY\": If the user's query appears to be answerable using information from OpenAI's official documentation, tools, models, APIs, or services (e.g., GPT, ChatGPT, embeddings, moderation API, usage guidelines).\n",
        "\n",
        "    2. \"10K_DOCUMENT_QUERY\": If the user's query pertains to a collection of documents from the 10k annual reports, datasets, or other structured documents, typically for research, analysis, or financial content.\n",
        "\n",
        "    3. \"INTERNET_QUERY\": If the query is neither related to OpenAI nor the 10k documents specifically, or if the information might require a broader search (e.g., news, trends, tools outside these platforms), route it here.\n",
        "\n",
        "    Your decision should be made by assessing the domain of the query.\n",
        "\n",
        "    Always respond in this valid JSON format:\n",
        "    {{\n",
        "        \"action\": \"OPENAI_QUERY\" or \"10K_DOCUMENT_QUERY\" or \"INTERNET_QUERY\",\n",
        "        \"reason\": \"brief justification\",\n",
        "        \"answer\": \"AT MAX 5 words answer. Leave empty if INTERNET_QUERY\"\n",
        "    }}\n",
        "\n",
        "    EXAMPLES:\n",
        "\n",
        "    - User: \"How to fine-tune GPT-3?\"\n",
        "    Response:\n",
        "    {{\n",
        "        \"action\": \"OPENAI_QUERY\",\n",
        "        \"reason\": \"Fine-tuning is OpenAI-specific\",\n",
        "        \"answer\": \"Use fine-tuning API\"\n",
        "    }}\n",
        "\n",
        "    - User: \"Where can I find the latest financial reports for the last 10 years?\"\n",
        "    Response:\n",
        "    {{\n",
        "        \"action\": \"10K_DOCUMENT_QUERY\",\n",
        "        \"reason\": \"Query related to annual reports\",\n",
        "        \"answer\": \"Access through document database\"\n",
        "    }}\n",
        "\n",
        "    - User: \"Top leadership styles in 2024\"\n",
        "    Response:\n",
        "    {{\n",
        "        \"action\": \"INTERNET_QUERY\",\n",
        "        \"reason\": \"Needs current leadership trends\",\n",
        "        \"answer\": \"\"\n",
        "    }}\n",
        "\n",
        "    - User: \"What's the difference between ChatGPT and Claude?\"\n",
        "    Response:\n",
        "    {{\n",
        "        \"action\": \"INTERNET_QUERY\",\n",
        "        \"reason\": \"Cross-comparison of different providers\",\n",
        "        \"answer\": \"\"\n",
        "    }}\n",
        "\n",
        "    Strictly follow this format for every query, and never deviate.\n",
        "    User: {user_query}\n",
        "    \"\"\"\n",
        "\n",
        "\n",
        "    try:\n",
        "        # Query the GPT-4 model with the router prompt and user input\n",
        "        response = openaiclient.chat.completions.create(\n",
        "            model=\"gpt-4\",\n",
        "            messages=[{\"role\": \"system\", \"content\": router_system_prompt}]\n",
        "        )\n",
        "\n",
        "        # Extract and parse the model's JSON response\n",
        "        task_response = response.choices[0].message.content\n",
        "        parsed_response = json.loads(task_response)\n",
        "        return parsed_response\n",
        "\n",
        "    # Handle OpenAI API errors (e.g., rate limits, authentication)\n",
        "    except OpenAIError as api_err:\n",
        "        return {\n",
        "            \"action\": \"INTERNET_QUERY\",\n",
        "            \"reason\": f\"OpenAI API error: {api_err}\",\n",
        "            \"answer\": \"\"\n",
        "        }\n",
        "\n",
        "    # Handle case where model response isn't valid JSON\n",
        "    except json.JSONDecodeError as json_err:\n",
        "        return {\n",
        "            \"action\": \"INTERNET_QUERY\",\n",
        "            \"reason\": f\"JSON parsing error: {json_err}\",\n",
        "            \"answer\": \"\"\n",
        "        }\n",
        "\n",
        "    # Catch-all for any other unforeseen issues\n",
        "    except Exception as err:\n",
        "        return {\n",
        "            \"action\": \"INTERNET_QUERY\",\n",
        "            \"reason\": f\"Unexpected error: {err}\",\n",
        "            \"answer\": \"\"\n",
        "        }\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "route_query(\"what is the revenue of uber in 2021?\")\n"
      ],
      "metadata": {
        "id": "5ilSsVBBv-KT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "210b20ae-e965-4f94-bb6d-a1561c28c0d8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'action': '10K_DOCUMENT_QUERY',\n",
              " 'reason': \"Uber's financial data, including its 2021 revenue, might be found in its annual report\",\n",
              " 'answer': \"Check Uber's 10K report\"}"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "route_query(\"What was Lyft's revenue growth rate in 2024 compared to 2023?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GHOx8W50oNN6",
        "outputId": "851ae485-e883-4b2e-90af-b60b9b3b68b9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'action': '10K_DOCUMENT_QUERY',\n",
              " 'reason': \"Need to study Lyft's annual reports\",\n",
              " 'answer': \"Check Lyft's 10K reports\"}"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "route_query(\"what was uber revenue in 2024?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G-9vRa5bpiKk",
        "outputId": "75dfd0b2-65c8-4c41-8f68-f6e5a14083ba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'action': '10K_DOCUMENT_QUERY',\n",
              " 'reason': \"Information likely available in Uber's 10K report\",\n",
              " 'answer': ''}"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "route_query(\"What is the purpose of the OpenAI moderation API?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dxX4VWsIsKB3",
        "outputId": "3ab9f4d8-367d-47a7-c0a3-96181eb61fcd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'action': 'OPENAI_QUERY',\n",
              " 'reason': \"The query is about OpenAI's product\",\n",
              " 'answer': 'Filters inappropriate content'}"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VrkE-V4PlClH"
      },
      "source": [
        "## 3. Setting Up Qdrant Vector Database for Agentic RAG\n",
        "In this step, we are connecting our agent to a pre-built vector database using Qdrant‚Äîa tool used to store and search document embeddings (numerical representations of text).\n",
        "\n",
        "What Are We Doing?\n",
        "We are loading an existing Qdrant database that was downloaded from a GitHub repository. This database already contains:\n",
        "\n",
        "- Vectorized OpenAI documentation\n",
        "- Vectorized 10-K financial filings\n",
        "\n",
        "By loading this saved data:\n",
        "\n",
        "- We save time (no need to re-embed the documents)\n",
        "- We enable fast similarity search to retrieve relevant text chunks\n",
        "\n",
        "This setup allows our system to perform semantic search, meaning it can understand the meaning of the user query and match it with the most relevant pieces of information stored in the database.\n",
        "\n",
        "\n",
        "### Why This Matters in Agentic RAG\n",
        "Once the router decides that the query should go to the OpenAI docs or the 10-K reports, our system uses Qdrant to:\n",
        "\n",
        "- Search for the most relevant pieces of text\n",
        "- Pass those to the model to generate a grounded answer\n",
        "\n",
        "So, this step is essential to support retrieval-augmented generation (RAG) within our agentic flow."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Data Sources:\n",
        "\n",
        "**10K Database: Lyft 2024 & Uber 2021 SEC filings**\n",
        "\n",
        "**OpenAI Docs: Official OpenAI documentation**\n",
        "\n",
        "For lecture demo purposes, the vecitr database has already been created and hosted on Github which we will clone here. In order to create your own embeddings, the notebook and data will be hosted and shared on github"
      ],
      "metadata": {
        "id": "yXAXLB2eCgSn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Clone the project repository that contains prebuilt vector data (e.g., Qdrant collections)\n",
        "# This includes document embeddings and configurations needed for retrieval (10-K, OpenAI docs)\n",
        "\n",
        "!git clone https://github.com/hamzafarooq/multi-agent-course.git\n"
      ],
      "metadata": {
        "id": "suqlk9P9YJfQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3ae6a469-b318-4ec1-92e6-891a4572db35"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'multi-agent-course'...\n",
            "remote: Enumerating objects: 120, done.\u001b[K\n",
            "remote: Counting objects: 100% (120/120), done.\u001b[K\n",
            "remote: Compressing objects: 100% (95/95), done.\u001b[K\n",
            "remote: Total 120 (delta 28), reused 35 (delta 3), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (120/120), 4.44 MiB | 13.42 MiB/s, done.\n",
            "Resolving deltas: 100% (28/28), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# üóÑÔ∏è Initializing Qdrant client with local path to vector database\n",
        "# The path points to prebuilt Qdrant collections (10-K and OpenAI docs) cloned from the repository\n",
        "# This enables fast, local retrieval of relevant document chunks based on semantic similarity\n",
        "client = QdrantClient(path=\"/content/multi-agent-course/Module_1/Agentic_RAG/qdrant_data\")\n"
      ],
      "metadata": {
        "id": "BB-p1nzYo91-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z90HaV0jm93H"
      },
      "source": [
        "## 4. Building the Retriever and RAG for Vector Databases\n",
        "In this section, we build the core logic that allows our agent to find relevant documents and generate grounded answers using them.\n",
        "\n",
        "###Step 1: Import the Embedding Model\n",
        "We start by importing the nomic-ai/nomic-embed-text-v1.5 model from Hugging Face. This model is used to convert any text (such as a user query) into a dense vector, known as an embedding. These embeddings capture the semantic meaning of text, allowing us to later compare and retrieve similar documents.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qM6mDo0InEji",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 582,
          "referenced_widgets": [
            "235308bfee754284b28f7947e2168982",
            "c774cb886aa7442faa6b4874fdaad2fe",
            "84e1155e2246411b8322586228034773",
            "078e61f31591461b9ca401f3c01b7220",
            "a917ef1cb7a840639d4477d4968c37f0",
            "edfa5dbe7bae4991be18128b4fd769a1",
            "565f8bc978df4f01b47bb559a20c040e",
            "c5be6c3aaa734a8cbd34a605a1ab68d3",
            "295d7b751f0148ec87d85f167d30d745",
            "8dbe2fdd180344e3823cb93f1b41b733",
            "b23b6ba9180f4f8886b849899392381a",
            "b68eba02bd084ebaa56a80d8b003b14d",
            "0696dcfa5d604c9dad87b9b4946fe212",
            "c677b567e0404b23a359c8ed8a741a4b",
            "2b90461880434a16810d43371ab74d7d",
            "38850d36cb844a47806befde98124188",
            "55ac5a96ff4b465586d8dfc9d027cbb5",
            "99f1ff61bf9946a9b51ca9591de9aa0f",
            "c0af8eefa42a42c8b33611113ea35249",
            "cf9ba2291a244c4093c1f273713fb79c",
            "b07a8c8d54d84aa0ac62937d1b7a61f7",
            "049fd3969b0f4686ae97ff758f3c4ab1",
            "723b35fbf5f8408f827723f7ff717e80",
            "275a9ee0148048b6bb93c9770ad6bb81",
            "489357fa807d4bb1b45eec65c2dc238c",
            "56395941c10b422fb9f230b57b5dd5db",
            "6c4c1cf9548a4051a0fe503453810de9",
            "5e8d44e69cba47259296135c1b8a717a",
            "9509f353876244ed9ff29b08de13e3e0",
            "7ec3287674434d639e63cc463efbcaae",
            "fab83ed6831640d3bf6edbd0ce912192",
            "56fa2e2dcfce4f23b59b187d45cca6fc",
            "56ba07e08bdf49959ee2f8252c7916f3",
            "e0df303e08c3419585c283cbe6102e3a",
            "60708fd0dd1445d3bbcef145ab292109",
            "fc270dbb7c534e7f965c7f6f5e70db5a",
            "e04bd3bdc986428dad7ca52525bdce8f",
            "599d8e1cd5f9418cbfb6a8607245ff7a",
            "3872b985c94c4635baa49f8417885a1d",
            "d05588e6e2a3468e8f62e805f51de794",
            "a4402872bffb45958f0293bcbf2fadf6",
            "80209095b1cd45899d0638a402003f5c",
            "cbd5b511e1764de58a72adefff495597",
            "852f3b2f24b345a2b97097a2fa161118",
            "e6c00d601fe6485eb9ec3bc7979a203d",
            "e6839ef953bd42d7933199cdd700c48a",
            "40a0c4d28dfd43afabf6fb731b3c0e4a",
            "42c1774d9dc64ce98ff92feb0e80921f",
            "f279248232e54f9784ac4e8d0b742625",
            "a2eb5335f5604dfd9aaa990baf46f686",
            "5424c172838e4c7ba8021cbe6efe4891",
            "6ac7cef1125142a8bbe006964bb40f85",
            "f6ef13ad79ed430fbe7f34a18522d904",
            "0cb153759ac14c5ebaaa7198edf9dc2d",
            "e32dd6f485dc44eea360d07302c60942",
            "ac32288ea9e1455c9f2bcdde79ddef2a",
            "d5a0cf77dd9649ad8048120e7524e62a",
            "b09f85e6dd8648c698936cd2113a8f72",
            "1cac8cd1a8c24625af1036838afc95ab",
            "f789b097889049f5bd343c6a4f6022ee",
            "de4bc84f73744ca3bd7b9986250b2875",
            "cd7a84569d34411883a48b820f19d63a",
            "da5fd396c4b44ca0800769b2fd35def9",
            "5cba8942e028470289d2709ee576c41c",
            "30e5387606914080a99108c0415ae47d",
            "78873e29fd004afa9ac1aab4feb68036",
            "da65d5ee14c74e4497cb27844dd5ac5d",
            "d8a6881236b244d6bbdd711035d05e1f",
            "d09bf2587e594473b50c4c02d574025d",
            "6781797081a64b47a675e49fadf69367",
            "4f016fe358ce462fb3f8fc3d6cf97704",
            "17e8f231cc6f441a89efb913de2918cb",
            "ef8acf34f1c14f6790ed7d3c6542a871",
            "c5c5223cf8374f27be702ae75c48024a",
            "693b05a975ed482e9cf86aa5d11f994a",
            "c2b0f498fa9148bf9e479bb71475d5e7",
            "4964fb23752e4785b6d9b8701bca3a57",
            "5ea80592d94d4cc1aff4fc20c53159b6",
            "22806a7a0333486ca39e7866752dec2e",
            "4df41647825541fc967d6502d90ad635",
            "b34ae6bea32b420bbe984f55c3f58775",
            "bea8f085e9c9425184ae4d78c7e70d06",
            "4e701799129f43158f0832d7e65a5f76",
            "8d01f84dc17c438c84741c1ddf439e45",
            "6da7ca01d9d9464fb9cc956bad1854e1",
            "3788a9c791464504bedf5bc5144b8c38",
            "7a352ef7d78c47f2bffd377ab08c747b",
            "bbc32b356aec4319a35a281b54a8f7df"
          ]
        },
        "outputId": "bc736e02-b840-4bd9-ddb4-db63522aba01"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/1.19k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "235308bfee754284b28f7947e2168982"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b68eba02bd084ebaa56a80d8b003b14d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/711k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "723b35fbf5f8408f827723f7ff717e80"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/695 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e0df303e08c3419585c283cbe6102e3a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/2.06k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e6c00d601fe6485eb9ec3bc7979a203d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "configuration_hf_nomic_bert.py:   0%|          | 0.00/1.96k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ac32288ea9e1455c9f2bcdde79ddef2a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "A new version of the following files was downloaded from https://huggingface.co/nomic-ai/nomic-bert-2048:\n",
            "- configuration_hf_nomic_bert.py\n",
            ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "modeling_hf_nomic_bert.py:   0%|          | 0.00/104k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "da65d5ee14c74e4497cb27844dd5ac5d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "A new version of the following files was downloaded from https://huggingface.co/nomic-ai/nomic-bert-2048:\n",
            "- modeling_hf_nomic_bert.py\n",
            ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n",
            "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
            "WARNING:huggingface_hub.file_download:Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/547M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5ea80592d94d4cc1aff4fc20c53159b6"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:transformers_modules.nomic-ai.nomic-bert-2048.7710840340a098cfb869c4f65e87cf2b1b70caca.modeling_hf_nomic_bert:<All keys matched successfully>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ 1.2799692   0.40158355 -3.5162656  -0.3981321   1.5919138 ]\n"
          ]
        }
      ],
      "source": [
        "# Load the tokenizer and embedding model from Hugging Face\n",
        "# This model converts raw text into dense vector representations (embeddings)\n",
        "# Used for similarity search in Qdrant during document retrieval\n",
        "text_tokenizer = AutoTokenizer.from_pretrained(\"nomic-ai/nomic-embed-text-v1.5\", trust_remote_code=True)\n",
        "text_model = AutoModel.from_pretrained(\"nomic-ai/nomic-embed-text-v1.5\", trust_remote_code=True)\n",
        "\n",
        "def get_text_embeddings(text):\n",
        "    \"\"\"\n",
        "    Converts input text into a dense embedding using the Nomic embedding model.\n",
        "    These embeddings are used to query Qdrant for semantically relevant document chunks.\n",
        "\n",
        "    Args:\n",
        "        text (str): The input text or query from the user.\n",
        "\n",
        "    Returns:\n",
        "        np.ndarray: A fixed-size vector representing the semantic meaning of the input.\n",
        "    \"\"\"\n",
        "    # Tokenize and prepare input for the model\n",
        "    inputs = text_tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True)\n",
        "\n",
        "    # Forward pass to get model outputs\n",
        "    outputs = text_model(**inputs)\n",
        "\n",
        "    # Take the mean across all token embeddings to get a single vector (pooled representation)\n",
        "    embeddings = outputs.last_hidden_state.mean(dim=1)\n",
        "\n",
        "    # Convert to NumPy array and detach from computation graph\n",
        "    return embeddings[0].detach().numpy()\n",
        "\n",
        "# Example usage: Generate and preview the embedding of a test sentence\n",
        "text = \"This is a test sentence.\"\n",
        "embeddings = get_text_embeddings(text)\n",
        "print(embeddings[:5])  # Print first 5 dimensions for inspection\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 2: Define the Embedding Function\n",
        "We then define a function get_text_embeddings() which:\n",
        "\n",
        "- Tokenizes the input text\n",
        "- Runs it through the model\n",
        "- Computes the average of all token embeddings\n",
        "- Returns a single vector that represents the full sentence\n",
        "\n",
        "This vector will be used to query Qdrant to find the most relevant document chunks based on similarity."
      ],
      "metadata": {
        "id": "nXOx47EKw2ir"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def rag_formatted_response(user_query: str, context: list):\n",
        "    \"\"\"\n",
        "    Generate a response to the user query using the provided context,\n",
        "    with article references formatted as [1][2], etc.\n",
        "\n",
        "    This function performs the final step in the RAG pipeline‚Äîsynthesizing an answer\n",
        "    from retrieved document chunks (context). It prompts the model to generate a\n",
        "    grounded response, explicitly citing sources using a reference format.\n",
        "\n",
        "    Args:\n",
        "        user_query (str): The user's original question.\n",
        "        context (list): List of text chunks retrieved from Qdrant (10-K or OpenAI docs).\n",
        "\n",
        "    Returns:\n",
        "        str: A generated response grounded in the retrieved context, with numbered citations.\n",
        "    \"\"\"\n",
        "\n",
        "    # Construct a RAG prompt that includes both:\n",
        "    # 1. The user's query\n",
        "    # 2. The supporting context documents\n",
        "    # The prompt instructs the model to answer using only the provided context,\n",
        "    # and to include citations like [1], [2], etc. based on chunk IDs or order.\n",
        "    rag_prompt = f\"\"\"\n",
        "       Based on the given context, answer the user query: {user_query}\\nContext:\\n{context}\n",
        "       and employ references to the ID of articles provided [ID], ensuring their relevance to the query.\n",
        "       The referencing should always be in the format of [1][2]... etc. </instructions>\n",
        "    \"\"\"\n",
        "\n",
        "    #  Call GPT-4o to generate the response using the RAG-style prompt\n",
        "    response = openaiclient.chat.completions.create(\n",
        "        model=\"gpt-4o\",\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": rag_prompt},\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    # Return the model's generated answer\n",
        "    return response.choices[0].message.content\n"
      ],
      "metadata": {
        "id": "3r6MeyRz8sv7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 3: Define the RAG Response Generator\n",
        "After retrieving relevant text chunks from Qdrant, we use the rag_formatted_response() function to generate a final answer. This function:\n",
        "\n",
        "- Takes the user query and the retrieved document chunks\n",
        "- Builds a prompt that asks the language model (GPT-4o) to answer the question using only the provided context\n",
        "- Instructs the model to include references like [1], [2] for traceability\n",
        "\n",
        "This ensures the output is not only informative but also grounded in actual retrieved data.\n",
        "\n",
        "Together, these two functions lay the foundation for combining retrieval (from vector DB) and generation (from LLM) ‚Äî the two pillars of a RAG system.\n",
        "\n"
      ],
      "metadata": {
        "id": "zdaeGcoCDw5w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def retrieve_and_response(user_query: str, action: str):\n",
        "    \"\"\"\n",
        "    Retrieves relevant text chunks from the appropriate Qdrant collection\n",
        "    based on the query type, then generates a response using RAG.\n",
        "\n",
        "    This function powers the retrieval and response generation pipeline\n",
        "    for queries that are classified as either OPENAI-related or 10-K related.\n",
        "    It uses semantic search to fetch relevant context from a Qdrant vector store\n",
        "    and then generates a response using that context via a RAG prompt.\n",
        "\n",
        "    Args:\n",
        "        user_query (str): The user's input question.\n",
        "        action (str): The classification label from the router (e.g., \"OPENAI_QUERY\", \"10K_DOCUMENT_QUERY\").\n",
        "\n",
        "    Returns:\n",
        "        str: A model-generated response grounded in retrieved documents, or an error message.\n",
        "    \"\"\"\n",
        "\n",
        "    # Define mapping of routing labels to their respective Qdrant collections\n",
        "    collections = {\n",
        "        \"OPENAI_QUERY\": \"opnai_data\",           # Collection of OpenAI documentation embeddings\n",
        "        \"10K_DOCUMENT_QUERY\": \"10k_data\"        # Collection of 10-K financial document embeddings\n",
        "    }\n",
        "\n",
        "    try:\n",
        "        # Ensure that the provided action is valid\n",
        "        if action not in collections:\n",
        "            return \"Invalid action type for retrieval.\"\n",
        "\n",
        "        # Step 1: Convert the user query into a dense vector (embedding)\n",
        "        try:\n",
        "            query = get_text_embeddings(user_query)\n",
        "        except Exception as embed_err:\n",
        "            return f\"Embedding error: {embed_err}\"  # Fail early if embedding fails\n",
        "\n",
        "        # Step 2: Retrieve top-matching chunks from the relevant Qdrant collection\n",
        "        try:\n",
        "            text_hits = client.query_points(\n",
        "                collection_name=collections[action],  # Choose the right collection based on routing\n",
        "                query=query,                          # The embedding of the user's query\n",
        "                limit=3                               # Fetch top 3 relevant chunks\n",
        "            ).points\n",
        "        except Exception as qdrant_err:\n",
        "            return f\"Vector DB query error: {qdrant_err}\"  # Handle Qdrant access issues\n",
        "\n",
        "        # Extract the raw content from the retrieved vector hits\n",
        "        contents = [point.payload['content'] for point in text_hits]\n",
        "\n",
        "        # If no relevant content is found, return early\n",
        "        if not contents:\n",
        "            return \"No relevant content found in the database.\"\n",
        "\n",
        "        # Step 3: Pass the retrieved context to the RAG model to generate a response\n",
        "        try:\n",
        "            response = rag_formatted_response(user_query, contents)\n",
        "            return response\n",
        "        except Exception as rag_err:\n",
        "            return f\"RAG response error: {rag_err}\"  # Handle generation failures\n",
        "\n",
        "    # Catch any unforeseen errors in the overall process\n",
        "    except Exception as err:\n",
        "        return f\"Unexpected error: {err}\"\n"
      ],
      "metadata": {
        "id": "hp0y2J1AgX2t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. Analyze, route, process compund query"
      ],
      "metadata": {
        "id": "AKEXtwBK1tT6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def route_query(user_query: str):\n",
        "    \"\"\"\n",
        "    Routes a user query to the appropriate source (OpenAI, 10k, or Internet).\n",
        "\n",
        "    This function acts as the 'brain' of the agentic RAG system. It uses GPT-4\n",
        "    to reason about the nature of the user's query and classify it into one of three routes.\n",
        "\n",
        "    Args:\n",
        "        user_query (str): The user's input question.\n",
        "\n",
        "    Returns:\n",
        "        dict: Classification output containing route, reasoning, and (optional) short answer.\n",
        "    \"\"\"\n",
        "    # Construct router system prompt\n",
        "    router_system_prompt = f\"\"\"\n",
        "    As a professional query router, your objective is to correctly classify user input into one of three categories based on the source most relevant for answering the query:\n",
        "\n",
        "    1. \"OPENAI_QUERY\": If the user's query appears to be answerable using information from OpenAI's official documentation, tools, models, APIs, or services.\n",
        "\n",
        "    2. \"10K_DOCUMENT_QUERY\": If the user's query pertains to a collection of documents from the 10k annual reports, datasets, or other structured documents.\n",
        "\n",
        "    3. \"INTERNET_QUERY\": If the query is neither related to OpenAI nor the 10k documents specifically, or if the information might require a broader search.\n",
        "\n",
        "    Always respond in this valid JSON format:\n",
        "    {{\n",
        "        \"action\": \"OPENAI_QUERY\" or \"10K_DOCUMENT_QUERY\" or \"INTERNET_QUERY\",\n",
        "        \"reason\": \"brief justification\",\n",
        "        \"answer\": \"AT MAX 5 words answer. Leave empty if INTERNET_QUERY\"\n",
        "    }}\n",
        "\n",
        "    User: {user_query}\n",
        "    \"\"\"\n",
        "\n",
        "    try:\n",
        "        # Query the GPT-4 model with the router prompt\n",
        "        response = openaiclient.chat.completions.create(\n",
        "            model=\"gpt-4\",\n",
        "            messages=[{\"role\": \"system\", \"content\": router_system_prompt}]\n",
        "        )\n",
        "\n",
        "        # Extract and parse the model's JSON response\n",
        "        task_response = response.choices[0].message.content\n",
        "        parsed_response = json.loads(task_response)\n",
        "        return parsed_response\n",
        "\n",
        "    except Exception as err:\n",
        "        # Default fallback if routing fails\n",
        "        return {\n",
        "            \"action\": \"INTERNET_QUERY\",\n",
        "            \"reason\": f\"Routing error: {err}\",\n",
        "            \"answer\": \"\"\n",
        "        }\n",
        "\n",
        "\n",
        "\n",
        "def analyze_compound_query(user_query):\n",
        "    \"\"\"\n",
        "    Enhanced compound query analyzer that better handles financial queries with multiple companies.\n",
        "    \"\"\"\n",
        "    # First check for OpenAI API + financial query\n",
        "    if \"openai\" in user_query.lower() and \" and \" in user_query.lower():\n",
        "        financial_terms = [\"revenue\", \"profit\", \"earnings\", \"financial\", \"income\", \"sales\"]\n",
        "        has_financial = any(term in user_query.lower() for term in financial_terms)\n",
        "\n",
        "        if has_financial:\n",
        "            # Split by \" and \"\n",
        "            parts = user_query.split(\" and \", 1)\n",
        "            if len(parts) == 2:\n",
        "                return parts\n",
        "\n",
        "    # Check for financial terms\n",
        "    financial_terms = [\"revenue\", \"profit\", \"earnings\", \"financial\", \"income\", \"sales\"]\n",
        "    is_financial = any(term in user_query.lower() for term in financial_terms)\n",
        "\n",
        "    # For financial queries, check for multiple companies\n",
        "    if is_financial:\n",
        "        companies = [\"uber\", \"lyft\", \"amazon\", \"google\", \"microsoft\", \"apple\", \"tesla\", \"facebook\", \"meta\"]\n",
        "        found_companies = []\n",
        "\n",
        "        for company in companies:\n",
        "            if company in user_query.lower():\n",
        "                found_companies.append(company)\n",
        "\n",
        "        # If multiple companies found in a financial query, it's definitely compound\n",
        "        if len(found_companies) >= 2:\n",
        "            print(f\"Financial query with companies: {found_companies}\")\n",
        "\n",
        "            # Extract year from the query\n",
        "            year_match = re.search(r'\\b(20\\d\\d)\\b', user_query)\n",
        "            year = year_match.group(1) if year_match else \"2024\"  # Default to 2024 if no year found\n",
        "\n",
        "            # Create separate queries for each company\n",
        "            sub_queries = []\n",
        "            for company in found_companies:\n",
        "                sub_query = f\"What was {company.capitalize()} revenue in {year}?\"\n",
        "                sub_queries.append(sub_query)\n",
        "\n",
        "            print(f\"Split into company-specific queries: {sub_queries}\")\n",
        "            return sub_queries\n",
        "\n",
        "    # If not a multi-company financial query, try the LLM-based approach\n",
        "    compound_check_prompt = f\"\"\"\n",
        "    You are a query analyzer that must determine if a query contains multiple distinct questions.\n",
        "\n",
        "    STRICT RULES:\n",
        "    1. If a query asks about MULTIPLE COMPANIES' financial data, it is ALWAYS compound.\n",
        "    2. If a query asks about OpenAI APIs AND company financial data, it is ALWAYS compound.\n",
        "    3. A query comparing different topics is NOT compound.\n",
        "\n",
        "    The query: \"{user_query}\"\n",
        "\n",
        "    Return ONLY a JSON object with this exact structure:\n",
        "    {{\"is_compound\": true/false, \"questions\": [\"question1\", \"question2\", ...]}}\n",
        "\n",
        "    If is_compound is true, the questions array MUST contain at least 2 elements.\n",
        "    \"\"\"\n",
        "\n",
        "    try:\n",
        "        compound_check_response = openaiclient.chat.completions.create(\n",
        "            model=\"gpt-4o\",\n",
        "            messages=[{\"role\": \"system\", \"content\": compound_check_prompt}],\n",
        "            response_format={\"type\": \"json_object\"}  # Force JSON response\n",
        "        )\n",
        "\n",
        "        # response_text = compound_check_response.choices[0].message.content\n",
        "        # print(f\"Compound analysis response: {response_text}\")\n",
        "\n",
        "        # Parse the result\n",
        "        result = json.loads(response_text)\n",
        "\n",
        "        if result.get(\"is_compound\", False) and len(result.get(\"questions\", [])) >= 2:\n",
        "            questions = result.get(\"questions\")\n",
        "            # print(f\"LLM-based compound query detection: {questions}\")\n",
        "            return questions\n",
        "\n",
        "    except Exception as e:\n",
        "        # print(f\"Error in LLM compound analysis: {e}\")\n",
        "        pass\n",
        "\n",
        "    # If all detection methods fail, return original query\n",
        "    return [user_query]\n",
        "\n",
        "\n",
        "def route_and_verify_query(query):\n",
        "    \"\"\"\n",
        "    Routes a single query and verifies document availability.\n",
        "    \"\"\"\n",
        "    # First check if this is a financial query about a specific company\n",
        "    try:\n",
        "        financial_keywords = [\"revenue\", \"earnings\", \"financial\", \"profit\", \"income\", \"sales\"]\n",
        "        is_financial_query = any(keyword in query.lower() for keyword in financial_keywords)\n",
        "\n",
        "        if is_financial_query:\n",
        "            # Extract company and year\n",
        "            entity_prompt = f\"\"\"\n",
        "            Extract ONLY the company name and year from this financial query.\n",
        "            Return ONLY a JSON object: {{\"company\": \"name\", \"year\": \"YYYY\"}}\n",
        "\n",
        "            Query: {query}\n",
        "            \"\"\"\n",
        "\n",
        "            entity_response = openaiclient.chat.completions.create(\n",
        "                model=\"gpt-4o\",\n",
        "                messages=[{\"role\": \"system\", \"content\": entity_prompt}],\n",
        "                response_format={\"type\": \"json_object\"}\n",
        "            )\n",
        "\n",
        "            response_text = entity_response.choices[0].message.content\n",
        "            # print(f\"Entity extraction response: {response_text}\")\n",
        "\n",
        "            entities = json.loads(response_text)\n",
        "            company = entities.get(\"company\", \"\").lower().strip()\n",
        "            year = entities.get(\"year\", \"\").strip()\n",
        "\n",
        "            # print(f\"Extracted company: '{company}', year: '{year}'\")\n",
        "\n",
        "            # Define available company-year combinations\n",
        "            available_data = [\n",
        "                {\"company\": \"uber\", \"year\": \"2021\"},\n",
        "                {\"company\": \"lyft\", \"year\": \"2024\"}\n",
        "            ]\n",
        "\n",
        "            # Check for exact matches in our database\n",
        "            for entry in available_data:\n",
        "                entry_company = entry[\"company\"].lower()\n",
        "                entry_year = entry[\"year\"]\n",
        "\n",
        "                # Normalize company names\n",
        "                company_normalized = company.replace(\"'s\", \"\").strip()\n",
        "                entry_company_normalized = entry_company.replace(\"'s\", \"\").strip()\n",
        "\n",
        "                company_match = (\n",
        "                    company_normalized == entry_company_normalized or\n",
        "                    entry_company_normalized in company_normalized\n",
        "                )\n",
        "                year_match = entry_year == year\n",
        "\n",
        "                # print(f\"Comparing: '{company_normalized}' with '{entry_company_normalized}', match: {company_match}\")\n",
        "                # print(f\"Comparing year: '{year}' with '{entry_year}', match: {year_match}\")\n",
        "\n",
        "                if company_match and year_match:\n",
        "                    # print(f\"MATCH FOUND: Financial data for {entry_company} {entry_year} exists\")\n",
        "\n",
        "                    # Route to 10K_DOCUMENT_QUERY\n",
        "                    return {\n",
        "                        \"query\": query,\n",
        "                        \"action\": \"10K_DOCUMENT_QUERY\",\n",
        "                        \"reason\": f\"Financial data for {entry_company} {entry_year} found in database\",\n",
        "                        \"verified\": True\n",
        "                    }\n",
        "\n",
        "            # If no match, route to internet\n",
        "            if company and year:\n",
        "                # print(f\"NO MATCH: Financial data for {company} {year} not found in database\")\n",
        "                return {\n",
        "                    \"query\": query,\n",
        "                    \"action\": \"INTERNET_QUERY\",\n",
        "                    \"reason\": f\"No financial data for {company} {year} in database\",\n",
        "                    \"verified\": True\n",
        "                }\n",
        "    except Exception as e:\n",
        "        # print(f\"Error in financial query check: {e}\")\n",
        "        pass\n",
        "\n",
        "    # Continue with general routing if it's not a financial query or we couldn't determine\n",
        "    try:\n",
        "        route_result = route_query(query)\n",
        "        action = route_result.get(\"action\")\n",
        "        reason = route_result.get(\"reason\")\n",
        "\n",
        "        # For OpenAI queries, we can trust the router\n",
        "        if action == \"OPENAI_QUERY\":\n",
        "            return {\n",
        "                \"query\": query,\n",
        "                \"action\": action,\n",
        "                \"reason\": reason,\n",
        "                \"verified\": True\n",
        "            }\n",
        "\n",
        "        # For all other cases, use the original route\n",
        "        return {\n",
        "            \"query\": query,\n",
        "            \"action\": action,\n",
        "            \"reason\": reason,\n",
        "            \"verified\": True\n",
        "        }\n",
        "    except Exception as e:\n",
        "        # Default to internet query for any errors\n",
        "        return {\n",
        "            \"query\": query,\n",
        "            \"action\": \"INTERNET_QUERY\",\n",
        "            \"reason\": f\"Routing error: {e}\",\n",
        "            \"verified\": True\n",
        "        }\n",
        "\n",
        "\n",
        "\n",
        "def process_multi_route_query(routes_info):\n",
        "    \"\"\"\n",
        "    Processes multiple routes for compound queries.\n",
        "\n",
        "    Args:\n",
        "        routes_info (list): List of route information dictionaries\n",
        "\n",
        "    Returns:\n",
        "        list: List of results from processing each route\n",
        "    \"\"\"\n",
        "    results = []\n",
        "\n",
        "    for route_info in routes_info:\n",
        "        query = route_info[\"query\"]\n",
        "        action = route_info[\"action\"]\n",
        "\n",
        "        try:\n",
        "            route_function = routes.get(action)\n",
        "            if route_function:\n",
        "                result = route_function(query, action)\n",
        "                results.append({\n",
        "                    \"query\": query,\n",
        "                    \"action\": action,\n",
        "                    \"result\": result\n",
        "                })\n",
        "            else:\n",
        "                results.append({\n",
        "                    \"query\": query,\n",
        "                    \"action\": action,\n",
        "                    \"result\": f\"Unsupported action: {action}\"\n",
        "                })\n",
        "        except Exception as e:\n",
        "            results.append({\n",
        "                \"query\": query,\n",
        "                \"action\": action,\n",
        "                \"result\": f\"Error processing: {str(e)}\"\n",
        "            })\n",
        "\n",
        "    return results\n",
        "\n",
        "def format_multi_results(results):\n",
        "    \"\"\"\n",
        "    Formats multiple results into a cohesive response.\n",
        "\n",
        "    Args:\n",
        "        results (list): List of query results\n",
        "\n",
        "    Returns:\n",
        "        str: Formatted response combining all results\n",
        "    \"\"\"\n",
        "    if len(results) == 1:\n",
        "        # Single result, just return it\n",
        "        return results[0][\"result\"]\n",
        "\n",
        "    # Multiple results, format them together\n",
        "    response = \"Here are the answers to your questions:\\n\\n\"\n",
        "\n",
        "    for i, result in enumerate(results):\n",
        "        response += f\"Question {i+1}: {result['query']}\\n\"\n",
        "        response += f\"Answer: {result['result']}\\n\\n\"\n",
        "\n",
        "    return response"
      ],
      "metadata": {
        "id": "qrdoeO7B10jU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5. Putting It All Together: Running the Agentic RAG\n",
        "In this final step, we combine everything into a single function that controls the entire Agentic RAG workflow. The agentic_rag() function acts as the main orchestrator of the system.\n",
        "\n",
        "Here‚Äôs what it does:\n",
        "\n",
        "- Prints the user's query for reference.\n",
        "- Uses the router function (powered by GPT) to decide which type of data source to use:\n",
        "  - OpenAI documentation\n",
        "  - 10-K financial reports\n",
        "- Internet search\n",
        "- Calls the correct function based on the route:\n",
        "- If it‚Äôs an OpenAI or 10-K query, it retrieves data from Qdrant and generates a RAG response.\n",
        "- If it‚Äôs an Internet query, it uses the ARES API to fetch live information.\n",
        "- Displays the final response, neatly formatted in the console.\n",
        "\n",
        "This step brings the agentic loop full circle‚Äîfrom understanding the question, reasoning about where to search, to finally responding with the best possible answer."
      ],
      "metadata": {
        "id": "yfYzErTYzhnK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dictionary that maps the route labels (decided by the router) to their respective functions\n",
        "# Each type of query is handled differently:\n",
        "# - OPENAI_QUERY and 10K_DOCUMENT_QUERY use document retrieval + RAG\n",
        "# - INTERNET_QUERY uses a web search API\n",
        "\n",
        "routes = {\n",
        "    \"OPENAI_QUERY\": retrieve_and_response,\n",
        "    \"10K_DOCUMENT_QUERY\": retrieve_and_response,\n",
        "    \"INTERNET_QUERY\": get_internet_content,\n",
        "}\n",
        "\n",
        "def agentic_rag(user_query: str):\n",
        "    \"\"\"\n",
        "    Enhanced main function that handles compound queries and document availability.\n",
        "    \"\"\"\n",
        "    # Terminal color codes\n",
        "    CYAN = \"\\033[96m\"\n",
        "    GREY = \"\\033[90m\"\n",
        "    BOLD = \"\\033[1m\"\n",
        "    RESET = \"\\033[0m\"\n",
        "\n",
        "    try:\n",
        "        # Print the user's original question\n",
        "        print(f\"{BOLD}{CYAN}üë§ User Query:{RESET} {user_query}\\n\")\n",
        "\n",
        "        # Step 1: Check if this is a compound query with our enhanced detector\n",
        "        sub_queries = analyze_compound_query(user_query)\n",
        "        is_compound = len(sub_queries) > 1\n",
        "\n",
        "        if is_compound:\n",
        "            print(f\"{GREY}üìç Compound Query Detected: {len(sub_queries)} questions{RESET}\\n\")\n",
        "\n",
        "        # Step 2: Process each sub-query independently\n",
        "        all_results = []\n",
        "\n",
        "        for i, query in enumerate(sub_queries):\n",
        "            # Get routing for this specific sub-query\n",
        "            route_info = route_and_verify_query(query)\n",
        "\n",
        "            # Display routing information\n",
        "            if is_compound:\n",
        "                print(f\"{GREY}Query {i+1}: {query}\")\n",
        "                print(f\"Selected Route: {route_info['action']}\")\n",
        "                print(f\"Reason: {route_info['reason']}\")\n",
        "                print(f\"‚öôÔ∏è Processing query {i+1}...{RESET}\\n\")\n",
        "            else:\n",
        "                print(f\"{GREY}üìç Selected Route: {route_info['action']}\")\n",
        "                print(f\"üìù Reason: {route_info['reason']}\")\n",
        "                print(f\"‚öôÔ∏è Processing query...{RESET}\\n\")\n",
        "\n",
        "            # Process this sub-query\n",
        "            try:\n",
        "                action = route_info['action']\n",
        "                route_function = routes.get(action)\n",
        "\n",
        "                if route_function:\n",
        "                    result = route_function(query, action)\n",
        "                    all_results.append({\n",
        "                        \"query\": query,\n",
        "                        \"action\": action,\n",
        "                        \"result\": result\n",
        "                    })\n",
        "                else:\n",
        "                    all_results.append({\n",
        "                        \"query\": query,\n",
        "                        \"action\": action,\n",
        "                        \"result\": f\"Unsupported action: {action}\"\n",
        "                    })\n",
        "            except Exception as e:\n",
        "                all_results.append({\n",
        "                    \"query\": query,\n",
        "                    \"action\": action,\n",
        "                    \"result\": f\"Error processing: {str(e)}\"\n",
        "                })\n",
        "\n",
        "        # Step 3: Format and display results\n",
        "        try:\n",
        "            print(f\"{BOLD}{CYAN}ü§ñ BOT RESPONSE:{RESET}\\n\")\n",
        "\n",
        "            if is_compound:\n",
        "                # Categorize the queries by type\n",
        "                financial_queries = []\n",
        "                api_queries = []\n",
        "                other_queries = []\n",
        "\n",
        "                for i, result_info in enumerate(all_results):\n",
        "                    query = result_info[\"query\"].lower()\n",
        "                    if any(term in query for term in [\"revenue\", \"earnings\", \"financial\", \"profit\", \"income\", \"sales\"]):\n",
        "                        financial_queries.append((i, result_info))\n",
        "                    elif \"api\" in query and \"openai\" in query:\n",
        "                        api_queries.append((i, result_info))\n",
        "                    else:\n",
        "                        other_queries.append((i, result_info))\n",
        "\n",
        "                # Check for multiple financial queries about companies\n",
        "                if len(financial_queries) > 1:\n",
        "                    # Extract company names and revenue data\n",
        "                    companies_info = {}\n",
        "\n",
        "                    for _, result_info in financial_queries:\n",
        "                        query = result_info[\"query\"].lower()\n",
        "                        result = result_info[\"result\"]\n",
        "\n",
        "                        for company in [\"uber\", \"lyft\", \"amazon\", \"google\", \"microsoft\", \"apple\"]:\n",
        "                            if company in query:\n",
        "                                # Store the company name and full result\n",
        "                                companies_info[company.capitalize()] = result\n",
        "                                break\n",
        "\n",
        "                    # Create a synthesized response for multiple companies\n",
        "                    if len(companies_info) > 1:\n",
        "                        companies = list(companies_info.keys())\n",
        "\n",
        "                        # Create an integrated financial comparison\n",
        "                        response_parts = []\n",
        "\n",
        "                        # Extract revenue values\n",
        "                        uber_revenue = None\n",
        "                        lyft_revenue = None\n",
        "\n",
        "                        if \"Uber\" in companies_info:\n",
        "                            import re\n",
        "                            uber_match = re.search(r'\\$\\d+(?:\\.\\d+)?\\s*billion', companies_info[\"Uber\"].lower())\n",
        "                            if uber_match:\n",
        "                                uber_revenue = uber_match.group(0)\n",
        "\n",
        "                        if \"Lyft\" in companies_info:\n",
        "                            import re\n",
        "                            lyft_match = re.search(r'\\$([\\d,]+,\\d+)', companies_info[\"Lyft\"])\n",
        "                            if lyft_match:\n",
        "                                lyft_revenue = lyft_match.group(0)\n",
        "\n",
        "                        # Create summary comparing both companies\n",
        "                        summary = f\"In 2024, \"\n",
        "                        if uber_revenue and lyft_revenue:\n",
        "                            summary += f\"Uber reported revenue of {uber_revenue} while Lyft reported {lyft_revenue}. \"\n",
        "                        elif uber_revenue:\n",
        "                            summary += f\"Uber reported revenue of {uber_revenue}. \"\n",
        "                        elif lyft_revenue:\n",
        "                            summary += f\"Lyft reported revenue of {lyft_revenue}. \"\n",
        "\n",
        "                        # Add growth comparison if available\n",
        "                        uber_growth = None\n",
        "                        lyft_growth = None\n",
        "\n",
        "                        if \"Uber\" in companies_info:\n",
        "                            growth_match = re.search(r'(\\d+)%\\s*increase', companies_info[\"Uber\"])\n",
        "                            if growth_match:\n",
        "                                uber_growth = growth_match.group(1)\n",
        "\n",
        "                        if \"Lyft\" in companies_info:\n",
        "                            growth_match = re.search(r'(\\d+)%\\s*increase', companies_info[\"Lyft\"])\n",
        "                            if growth_match:\n",
        "                                lyft_growth = growth_match.group(1)\n",
        "\n",
        "                        if uber_growth and lyft_growth:\n",
        "                            summary += f\"Both companies showed significant growth, with Uber growing by {uber_growth}% and Lyft by {lyft_growth}% compared to 2023.\"\n",
        "                        elif uber_growth:\n",
        "                            summary += f\"Uber showed growth of {uber_growth}% compared to 2023.\"\n",
        "                        elif lyft_growth:\n",
        "                            summary += f\"Lyft showed growth of {lyft_growth}% compared to 2023.\"\n",
        "\n",
        "                        # Add the synthesized summary to response\n",
        "                        response_parts.append(summary)\n",
        "\n",
        "                        # Add detailed information section\n",
        "                        response_parts.append(\"\\nDetailed information:\")\n",
        "\n",
        "                        for company in companies:\n",
        "                            response_parts.append(f\"\\n## {company}\")\n",
        "\n",
        "                            # Extract key details from the company's result\n",
        "                            result_lines = companies_info[company].split('\\n')\n",
        "                            # Get first paragraph (usually contains the main revenue info)\n",
        "                            for line in result_lines:\n",
        "                                if line.strip() and \"revenue\" in line.lower() and \"$\" in line:\n",
        "                                    response_parts.append(line.strip())\n",
        "                                    break\n",
        "\n",
        "                        # Format the final synthesized response\n",
        "                        combined_response = \"\\n\".join(response_parts)\n",
        "                        print(combined_response)\n",
        "\n",
        "                    else:\n",
        "                        # If we couldn't extract company data properly, fall back to standard format\n",
        "                        combined_response = \"\"\n",
        "                        for i, result_info in enumerate(all_results):\n",
        "                            query_part = result_info['query']\n",
        "                            result_part = result_info['result']\n",
        "                            combined_response += f\"Question {i+1}: {query_part}\\n\"\n",
        "                            combined_response += f\"Answer: {result_part}\\n\\n\"\n",
        "                        print(combined_response)\n",
        "\n",
        "                # Handle OpenAI API + financial query mix\n",
        "                elif api_queries and financial_queries:\n",
        "                    # Get the API explanation and financial data\n",
        "                    api_result = None\n",
        "                    financial_result = None\n",
        "                    financial_company = None\n",
        "\n",
        "                    for _, result_info in api_queries:\n",
        "                        api_result = result_info[\"result\"]\n",
        "\n",
        "                    for _, result_info in financial_queries:\n",
        "                        financial_result = result_info[\"result\"]\n",
        "                        # Determine which company the financial data is about\n",
        "                        query = result_info[\"query\"].lower()\n",
        "                        for company in [\"uber\", \"lyft\", \"amazon\", \"google\", \"microsoft\", \"apple\"]:\n",
        "                            if company in query:\n",
        "                                financial_company = company.capitalize()\n",
        "                                break\n",
        "\n",
        "                    # Create an integrated response\n",
        "                    response_parts = []\n",
        "\n",
        "                    # Add introduction\n",
        "                    response_parts.append(\"Here's information about both the OpenAI Assistants API and the financial data you requested:\")\n",
        "\n",
        "                    # Add API overview\n",
        "                    response_parts.append(\"\\n## OpenAI Assistants API\")\n",
        "                    if api_result:\n",
        "                        # Extract first paragraph of API explanation (main overview)\n",
        "                        first_para = None\n",
        "                        for para in api_result.split('\\n\\n'):\n",
        "                            if para.strip() and \"OpenAI\" in para and \"API\" in para:\n",
        "                                first_para = para.strip()\n",
        "                                break\n",
        "                        if first_para:\n",
        "                            response_parts.append(first_para)\n",
        "\n",
        "                    # Add financial overview\n",
        "                    if financial_company:\n",
        "                        response_parts.append(f\"\\n## {financial_company}'s Financial Performance\")\n",
        "                    else:\n",
        "                        response_parts.append(\"\\n## Financial Data\")\n",
        "\n",
        "                    if financial_result:\n",
        "                        # Extract main financial information\n",
        "                        for line in financial_result.split('\\n'):\n",
        "                            if line.strip() and \"revenue\" in line.lower() and \"$\" in line:\n",
        "                                response_parts.append(line.strip())\n",
        "                                break\n",
        "\n",
        "                    # Add detailed sections\n",
        "                    response_parts.append(\"\\n## Detailed Information\")\n",
        "                    response_parts.append(\"\\n### OpenAI Assistants API Details\")\n",
        "                    if api_result:\n",
        "                        # Look for key points or features section\n",
        "                        key_points = None\n",
        "                        lines = api_result.split('\\n')\n",
        "                        for i, line in enumerate(lines):\n",
        "                            if \"key points\" in line.lower() or \"features\" in line.lower():\n",
        "                                # Include this line and next few lines\n",
        "                                key_points = '\\n'.join(lines[i:i+5])\n",
        "                                break\n",
        "\n",
        "                        if key_points:\n",
        "                            response_parts.append(key_points)\n",
        "                        else:\n",
        "                            # If no key points found, include a portion of the original\n",
        "                            shortened_api = '\\n'.join(api_result.split('\\n')[:5])\n",
        "                            response_parts.append(shortened_api)\n",
        "\n",
        "                    # Add financial details\n",
        "                    if financial_company:\n",
        "                        response_parts.append(f\"\\n### {financial_company} Financial Details\")\n",
        "                    else:\n",
        "                        response_parts.append(\"\\n### Financial Details\")\n",
        "\n",
        "                    if financial_result:\n",
        "                        # Include the key financial metrics\n",
        "                        financial_metrics = None\n",
        "                        for para in financial_result.split('\\n\\n'):\n",
        "                            if para.strip() and \"$\" in para and (\"increase\" in para.lower() or \"growth\" in para.lower()):\n",
        "                                financial_metrics = para.strip()\n",
        "                                break\n",
        "\n",
        "                        if financial_metrics:\n",
        "                            response_parts.append(financial_metrics)\n",
        "                        else:\n",
        "                            # If no specific metrics found, include beginning of financial result\n",
        "                            shortened_financial = financial_result.split('\\n\\n')[0] if '\\n\\n' in financial_result else financial_result\n",
        "                            response_parts.append(shortened_financial)\n",
        "\n",
        "                    # Format the final synthesized response\n",
        "                    combined_response = \"\\n\".join(response_parts)\n",
        "                    print(combined_response)\n",
        "\n",
        "                else:\n",
        "                    # Standard format for other compound queries\n",
        "                    combined_response = \"\"\n",
        "                    for i, result_info in enumerate(all_results):\n",
        "                        query_part = result_info['query']\n",
        "                        result_part = result_info['result']\n",
        "                        combined_response += f\"Question {i+1}: {query_part}\\n\"\n",
        "                        combined_response += f\"Answer: {result_part}\\n\\n\"\n",
        "                    print(combined_response)\n",
        "            else:\n",
        "                # Single result for non-compound queries\n",
        "                print(f\"{all_results[0]['result']}\\n\")\n",
        "        except Exception as err:\n",
        "            print(f\"{BOLD}{CYAN}ü§ñ BOT RESPONSE:{RESET}\\n\")\n",
        "            print(f\"Unexpected error occurred in result formatting: {err}\\n\")\n",
        "    except Exception as err:\n",
        "        print(f\"{BOLD}{CYAN}ü§ñ BOT RESPONSE:{RESET}\\n\")\n",
        "        print(f\"Unexpected error occurred in query processing: {err}\\n\")\n"
      ],
      "metadata": {
        "id": "ssG-BM9GpT-p"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "agentic_rag(\"what was uber revenue in 2021?\")"
      ],
      "metadata": {
        "id": "0-rTHJpGDTea",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ba4db24a-1a14-4a26-e7a9-3d37333f9071"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m\u001b[96müë§ User Query:\u001b[0m what was uber revenue in 2021?\n",
            "\n",
            "\u001b[90müìç Selected Route: 10K_DOCUMENT_QUERY\n",
            "üìù Reason: Financial data for uber 2021 found in database\n",
            "‚öôÔ∏è Processing query...\u001b[0m\n",
            "\n",
            "\u001b[1m\u001b[96mü§ñ BOT RESPONSE:\u001b[0m\n",
            "\n",
            "Uber's revenue in 2021 was $17,455 million [1].\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "agentic_rag(\"what was lyft revenue in 2024?\")"
      ],
      "metadata": {
        "id": "TncVUsVpu3WC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2ec0d39e-6460-4f66-ac0b-79f1e15b7dfc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m\u001b[96müë§ User Query:\u001b[0m what was lyft revenue in 2024?\n",
            "\n",
            "\u001b[90müìç Selected Route: 10K_DOCUMENT_QUERY\n",
            "üìù Reason: The revenue of Lyft in 2024 can be found in their annual 10k report for that year.\n",
            "‚öôÔ∏è Processing query...\u001b[0m\n",
            "\n",
            "\u001b[1m\u001b[96mü§ñ BOT RESPONSE:\u001b[0m\n",
            "\n",
            "Lyft's revenue for the year ended December 31, 2024, was $5,786,016,000, which represents a 31% increase compared to the previous year [1].\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "agentic_rag(\"what was uber revenue in 2024?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "32sntZwwX1ll",
        "outputId": "15fa8b7a-0b9c-4296-985e-8f4b732add03"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m\u001b[96müë§ User Query:\u001b[0m what was uber revenue in 2024?\n",
            "\n",
            "\u001b[90müìç Selected Route: INTERNET_QUERY\n",
            "üìù Reason: The data about Uber's revenue in 2024 is not available in OpenAI's documentation or in a 10k documents collection, and would require an internet search.\n",
            "‚öôÔ∏è Processing query...\u001b[0m\n",
            "\n",
            "Getting your response from the internet üåê ...\n",
            "\u001b[1m\u001b[96mü§ñ BOT RESPONSE:\u001b[0m\n",
            "\n",
            "Uber Technologies generated just under 44 billion U.S. dollars in net revenue in 2024. \n",
            "\n",
            "Here are some additional details regarding Uber's financial performance in 2024:\n",
            "\n",
            "1. **Total Revenue**: \n",
            "   - The reported revenue for Uber in 2024 was approximately $44.0 billion, reflecting an 18% increase from the previous year (2023).\n",
            "   - Other sources also confirm similar figures, with reports indicating revenues around $43.97 billion.\n",
            "\n",
            "2. **Quarterly Breakdown**:\n",
            "   - **Q1 2024**: Revenue grew 15% year-over-year to $10.1 billion.\n",
            "   - **Q2 2024**: Revenue reached $3.3 billion, with delivery revenue growing 8% year-over-year.\n",
            "   - **Q3 2024**: Revenue was reported at $1.3 billion for the freight segment.\n",
            "   - **Q4 2024**: The mobility segment reported $6.91 billion in revenue, up 25% from the previous year.\n",
            "\n",
            "3. **Financial Reports**: \n",
            "   - The financial results for the full year were announced on February 27, 2025, providing a comprehensive overview of Uber's performance.\n",
            "\n",
            "For more detailed financial insights, you can refer to the following sources:\n",
            "- [Uber revenue worldwide 2013-2024 - Statista](https://www.statista.com/statistics/550635/uber-global-net-revenue/)\n",
            "- [Uber Announces Results for Fourth Quarter and Full Year 2024](https://investor.uber.com/news-events/news/press-release-details/2025/Uber-Announces-Results-for-Fourth-Quarter-and-Full-Year-2024/default.aspx)\n",
            "- [Uber Technologies Full Year 2024 Earnings: EPS Beats Expectations](https://finance.yahoo.com/news/uber-technologies-full-2024-earnings-132735851.html)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "agentic_rag(\"List me down new LLMs\")"
      ],
      "metadata": {
        "id": "Mdb97ckP6y2h",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "728c35fa-8b9f-4f78-88a2-594105057f83"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m\u001b[96müë§ User Query:\u001b[0m List me down new LLMs\n",
            "\n",
            "\u001b[90müìç Selected Route: INTERNET_QUERY\n",
            "üìù Reason: The query is contextual and not specific to OpenAI or 10K documents. It could refer to programs, regulation, or something else related to LLMs (possibly referring to Master of Laws). An internet search would give the most comprehensive and updated results.\n",
            "‚öôÔ∏è Processing query...\u001b[0m\n",
            "\n",
            "Getting your response from the internet üåê ...\n",
            "\u001b[1m\u001b[96mü§ñ BOT RESPONSE:\u001b[0m\n",
            "\n",
            "1. **New Large Language Models in 2023:**\n",
            "   - 2023 has been a significant year for the development of large language models (LLMs), with numerous new models emerging at a rapid pace.\n",
            "   - The year saw a rise in small LLMs, particularly decoder-style transformers, with new pretrained models being released monthly.\n",
            "   - Notable models include:\n",
            "     - **GPT-4**: A multimodal model that has gained attention for its capabilities.\n",
            "     - **BLOOM**: An open-access model that has been highlighted for its accessibility.\n",
            "   - The landscape of LLMs in 2023 reflects a diverse range of applications and innovations, catering to various needs in natural language processing.\n",
            "\n",
            "2. **Additional Resources:**\n",
            "   - For a comprehensive overview of the best LLMs in 2023, you can refer to the following articles:\n",
            "     - [2023, year of open LLMs - Hugging Face](https://huggingface.co/blog/2023-in-llms)\n",
            "     - [13 Best Large Language Models In 2023 - Multimodal.dev](https://www.multimodal.dev/post/13-best-large-language-models-in-2024)\n",
            "     - [2023 Was the Year of Large Language Models: Then and Now - ODSC](https://odsc.medium.com/2023-was-the-year-of-large-language-models-then-and-now-924d34f3b6a9)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "agentic_rag(\"how to work with chat completions?\")"
      ],
      "metadata": {
        "id": "wpO6W8peh1qO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "668f9e56-57e8-44ce-b4c4-c517ce282820"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m\u001b[96müë§ User Query:\u001b[0m how to work with chat completions?\n",
            "\n",
            "\u001b[90müìç Selected Route: OPENAI_QUERY\n",
            "üìù Reason: The question queries the operation of chat completions, which is covered in OpenAI's API and documentation.\n",
            "‚öôÔ∏è Processing query...\u001b[0m\n",
            "\n",
            "\u001b[1m\u001b[96mü§ñ BOT RESPONSE:\u001b[0m\n",
            "\n",
            "To work with chat completions using the OpenAI API, you can follow these steps:\n",
            "\n",
            "1. **Retrieve Chat Messages**: Use the endpoint to get the list of chat messages from a specific chat completion. You can specify parameters such as `completion_id`, the number of messages to retrieve (`limit`), and the sort order (`order`). For example, to send a request, you use:\n",
            "   ```bash\n",
            "   curl https://api.openai.com/v1/chat/completions/chat_abc123/messages \\\n",
            "     -H \"Authorization: Bearer $OPENAI_API_KEY\" \\\n",
            "     -H \"Content-Type: application/json\"\n",
            "   ```\n",
            "\n",
            "2. **Get Chat Completion**: You can fetch a specific chat completion object based on its ID (`completion_id`). This will give you details about the completion such as the model used, tokens utilized, and the full response. The request can be made like this:\n",
            "   ```bash\n",
            "   curl https://api.openai.com/v1/chat/completions/chatcmpl-abc123 \\\n",
            "     -H \"Authorization: Bearer $OPENAI_API_KEY\" \\\n",
            "     -H \"Content-Type: application/json\"\n",
            "   ```\n",
            "\n",
            "3. **Streaming Options**: If you prefer to stream chat completions in real-time, you'll receive chunks of completions using server-sent events. This approach is particularly helpful for real-time applications.\n",
            "\n",
            "4. **Metadata Filtration**: While listing stored chat completions, you can use query parameters like `after`, `limit`, and `metadata` to filter the chat completions as needed.\n",
            "\n",
            "These operations allow you to effectively manage chat completions and integrate them into your application ([1][2]).\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3PDb2dwa68E7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Assignment: Implement sub-query division"
      ],
      "metadata": {
        "id": "DKagaRyI4jaK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In our current agentic retrieval-augmented generation (RAG) setup, there's a key limitation: when a user submits a query that contains multiple distinct questions phrased as a single input, the system treats it as a single unified search. As a result, the retrieval engine performs only one operation on the vector databases or external tools, which often leads to incomplete or less relevant results.\n",
        "\n",
        "\n",
        "To address this, the assignment introduces a new functionality called subquery division. This involves breaking down complex, compound queries into multiple, focused subqueries. Each subquery is processed independently, allowing the system to retrieve more accurate and context-specific information. By handling these subqueries separately, the agent can generate more complete and relevant responses."
      ],
      "metadata": {
        "id": "JZvmbi0QxPzD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Add this code cell at the end of the notebook\n",
        "\n",
        "print(\"--- Running Agentic RAG Examples ---\")\n",
        "\n",
        "# Example 1: Query expected to route to OPENAI_QUERY\n",
        "#print(\"\\\\n\" + \"=\"*30 + \" Example 1: OpenAI Query \" + \"=\"*30)\n",
        "#agentic_rag(\"What is the purpose of the OpenAI moderation API?\")\n",
        "\n",
        "# Example 2: Query expected to route to 10K_DOCUMENT_QUERY (and find data)\n",
        "#print(\"\\\\n\" + \"=\"*30 + \" Example 2: 10K Query (Success) \" + \"=\"*30)\n",
        "# Use Lyft 2024 data which exists in the Qdrant DB provided\n",
        "#agentic_rag(\"What was Lyft's revenue growth rate in 2024 compared to 2023?\")\n",
        "\n",
        "# Example 3: Query expected to route directly to INTERNET_QUERY\n",
        "#print(\"\\\\n\" + \"=\"*30 + \" Example 3: Direct Internet Query \" + \"=\"*30)\n",
        "#agentic_rag(\"What are the latest advancements in renewable energy technology?\")\n",
        "\n",
        "# Example 4: Query expected to route to 10K_DOCUMENT_QUERY, fail, and fallback to INTERNET_QUERY\n",
        "print(\"\\\\n\" + \"=\"*30 + \" Example 4: 10K Query (Fallback) \" + \"=\"*30)\n",
        "# Use Uber 2024, which is NOT in the Qdrant DB provided (only Uber 2021 is)\n",
        "# This assumes retrieve_and_response correctly returns DATA_NOT_FOUND_SIGNAL\n",
        "agentic_rag(\"What was Uber's revenue in 2024?\")\n",
        "\n",
        "# Example 5: Compound Query testing sub-query splitting and potential fallback\n",
        "print(\"\\\\n\" + \"=\"*30 + \" Example 5: Compound Query (Sub-queries + Fallback) \" + \"=\"*30)\n",
        "agentic_rag(\"Explain the OpenAI Assistants API and what was Lyft revenue in 2024?\")\n",
        "\n",
        "# Example 6: Another compound query mixing successful 10K and fallback 10K\n",
        "print(\"\\\\n\" + \"=\"*30 + \" Example 6: Compound Query (Mixed 10K Success/Fallback) \" + \"=\"*30)\n",
        "agentic_rag(\"What was Lyft revenue in 2024 and what was Uber revenue in 2024?\")\n",
        "\n",
        "\n",
        "print(\"\\\\n\" + \"=\"*30 + \" Examples Complete \" + \"=\"*30)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1uYJ9Q7LlHyt",
        "outputId": "a55a8bb7-a627-431a-e1bd-92063e394e75"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Running Agentic RAG Examples ---\n",
            "\\n============================== Example 4: 10K Query (Fallback) ==============================\n",
            "\u001b[1m\u001b[96müë§ User Query:\u001b[0m What was Uber's revenue in 2024?\n",
            "\n",
            "\u001b[90müìç Selected Route: INTERNET_QUERY\n",
            "üìù Reason: No financial data for uber 2024 in database\n",
            "‚öôÔ∏è Processing query...\u001b[0m\n",
            "\n",
            "Getting your response from the internet üåê ...\n",
            "\u001b[1m\u001b[96mü§ñ BOT RESPONSE:\u001b[0m\n",
            "\n",
            "Uber's revenue in 2024 was approximately $44 billion. This figure represents an 18% increase from the previous year, 2023. \n",
            "\n",
            "Here are some additional details regarding Uber's financial performance in 2024:\n",
            "\n",
            "1. **Total Revenue**: \n",
            "   - Uber Technologies generated just under $44 billion in net revenue for the year.\n",
            "   - Specific reports indicate the revenue was around $43.978 billion.\n",
            "\n",
            "2. **Quarterly Breakdown**:\n",
            "   - **Q1 2024**: Revenue grew to $10.1 billion, a 15% increase year-over-year.\n",
            "   - **Q2 2024**: Revenue reached $3.3 billion, with delivery revenue growing 8% year-over-year.\n",
            "   - **Q3 2024**: Revenue was reported at $1.3 billion, with freight revenue increasing 2% year-over-year.\n",
            "   - **Q4 2024**: The mobility segment reported $6.91 billion in revenue, up 25% from the previous year.\n",
            "\n",
            "3. **Growth Factors**: The increase in revenue was driven by growth in both the mobility and delivery segments, reflecting a strong demand for Uber's services.\n",
            "\n",
            "For further details, you can refer to the following sources:\n",
            "- [Statista - Uber revenue worldwide 2013-2024](https://www.statista.com/statistics/550635/uber-global-net-revenue/)\n",
            "- [Yahoo Finance - Uber Technologies Full Year 2024 Earnings](https://finance.yahoo.com/news/uber-technologies-full-2024-earnings-132735851.html)\n",
            "- [Uber Investor Relations - Q4 and Full Year 2024 Results](https://investor.uber.com/news-events/news/press-release-details/2025/Uber-Announces-Results-for-Fourth-Quarter-and-Full-Year-2024/default.aspx)\n",
            "\n",
            "\\n============================== Example 5: Compound Query (Sub-queries + Fallback) ==============================\n",
            "\u001b[1m\u001b[96müë§ User Query:\u001b[0m Explain the OpenAI Assistants API and what was Lyft revenue in 2024?\n",
            "\n",
            "\u001b[90müìç Compound Query Detected: 2 questions\u001b[0m\n",
            "\n",
            "\u001b[90mQuery 1: Explain the OpenAI Assistants API\n",
            "Selected Route: OPENAI_QUERY\n",
            "Reason: The query is directly related to OpenAI's APIs, specifications can be found in official OpenAI's documentation.\n",
            "‚öôÔ∏è Processing query 1...\u001b[0m\n",
            "\n",
            "\u001b[90mQuery 2: what was Lyft revenue in 2024?\n",
            "Selected Route: 10K_DOCUMENT_QUERY\n",
            "Reason: Financial data for lyft 2024 found in database\n",
            "‚öôÔ∏è Processing query 2...\u001b[0m\n",
            "\n",
            "\u001b[1m\u001b[96mü§ñ BOT RESPONSE:\u001b[0m\n",
            "\n",
            "Here's information about both the OpenAI Assistants API and the financial data you requested:\n",
            "\n",
            "## OpenAI Assistants API\n",
            "The OpenAI Assistants API allows users to interact with \"assistants,\" which are entities powered by large language models like GPT-4 that can perform various tasks. These assistants follow instructions and may have access to tools that enable them to handle more complex tasks, such as running code or retrieving information. The API provides endpoints to manage these assistants, including creating, retrieving, and modifying them.\n",
            "\n",
            "## Lyft's Financial Performance\n",
            "Lyft's revenue in 2024 was $5,786,016,000, which represents a 31% increase from the previous year [1].\n",
            "\n",
            "## Detailed Information\n",
            "\n",
            "### OpenAI Assistants API Details\n",
            "The OpenAI Assistants API allows users to interact with \"assistants,\" which are entities powered by large language models like GPT-4 that can perform various tasks. These assistants follow instructions and may have access to tools that enable them to handle more complex tasks, such as running code or retrieving information. The API provides endpoints to manage these assistants, including creating, retrieving, and modifying them.\n",
            "\n",
            "For instance, you can retrieve an assistant using an API call like this:\n",
            "```\n",
            "GET https://api.openai.com/v1/assistants/{assistant_id}\n",
            "\n",
            "### Lyft Financial Details\n",
            "Lyft's revenue in 2024 was $5,786,016,000, which represents a 31% increase from the previous year [1].\n",
            "\\n============================== Example 6: Compound Query (Mixed 10K Success/Fallback) ==============================\n",
            "\u001b[1m\u001b[96müë§ User Query:\u001b[0m What was Lyft revenue in 2024 and what was Uber revenue in 2024?\n",
            "\n",
            "Financial query with companies: ['uber', 'lyft']\n",
            "Split into company-specific queries: ['What was Uber revenue in 2024?', 'What was Lyft revenue in 2024?']\n",
            "\u001b[90müìç Compound Query Detected: 2 questions\u001b[0m\n",
            "\n",
            "\u001b[90mQuery 1: What was Uber revenue in 2024?\n",
            "Selected Route: INTERNET_QUERY\n",
            "Reason: No financial data for uber 2024 in database\n",
            "‚öôÔ∏è Processing query 1...\u001b[0m\n",
            "\n",
            "Getting your response from the internet üåê ...\n",
            "\u001b[90mQuery 2: What was Lyft revenue in 2024?\n",
            "Selected Route: 10K_DOCUMENT_QUERY\n",
            "Reason: Financial data for lyft 2024 found in database\n",
            "‚öôÔ∏è Processing query 2...\u001b[0m\n",
            "\n",
            "\u001b[1m\u001b[96mü§ñ BOT RESPONSE:\u001b[0m\n",
            "\n",
            "In 2024, Uber reported revenue of $44.0 billion while Lyft reported $5,786,016,000. Both companies showed significant growth, with Uber growing by 18% and Lyft by 31% compared to 2023.\n",
            "\n",
            "Detailed information:\n",
            "\n",
            "## Uber\n",
            "1. **Total Revenue**: Approximately $44.0 billion.\n",
            "\n",
            "## Lyft\n",
            "Lyft's revenue in 2024 was $5,786,016,000, which represented a 31% increase from the previous year (2023), where the revenue was $4,403,589,000 [1].\n",
            "\\n============================== Examples Complete ==============================\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "235308bfee754284b28f7947e2168982": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c774cb886aa7442faa6b4874fdaad2fe",
              "IPY_MODEL_84e1155e2246411b8322586228034773",
              "IPY_MODEL_078e61f31591461b9ca401f3c01b7220"
            ],
            "layout": "IPY_MODEL_a917ef1cb7a840639d4477d4968c37f0"
          }
        },
        "c774cb886aa7442faa6b4874fdaad2fe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_edfa5dbe7bae4991be18128b4fd769a1",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_565f8bc978df4f01b47bb559a20c040e",
            "value": "tokenizer_config.json:‚Äá100%"
          }
        },
        "84e1155e2246411b8322586228034773": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c5be6c3aaa734a8cbd34a605a1ab68d3",
            "max": 1191,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_295d7b751f0148ec87d85f167d30d745",
            "value": 1191
          }
        },
        "078e61f31591461b9ca401f3c01b7220": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8dbe2fdd180344e3823cb93f1b41b733",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_b23b6ba9180f4f8886b849899392381a",
            "value": "‚Äá1.19k/1.19k‚Äá[00:00&lt;00:00,‚Äá63.1kB/s]"
          }
        },
        "a917ef1cb7a840639d4477d4968c37f0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "edfa5dbe7bae4991be18128b4fd769a1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "565f8bc978df4f01b47bb559a20c040e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c5be6c3aaa734a8cbd34a605a1ab68d3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "295d7b751f0148ec87d85f167d30d745": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8dbe2fdd180344e3823cb93f1b41b733": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b23b6ba9180f4f8886b849899392381a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b68eba02bd084ebaa56a80d8b003b14d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0696dcfa5d604c9dad87b9b4946fe212",
              "IPY_MODEL_c677b567e0404b23a359c8ed8a741a4b",
              "IPY_MODEL_2b90461880434a16810d43371ab74d7d"
            ],
            "layout": "IPY_MODEL_38850d36cb844a47806befde98124188"
          }
        },
        "0696dcfa5d604c9dad87b9b4946fe212": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_55ac5a96ff4b465586d8dfc9d027cbb5",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_99f1ff61bf9946a9b51ca9591de9aa0f",
            "value": "vocab.txt:‚Äá100%"
          }
        },
        "c677b567e0404b23a359c8ed8a741a4b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c0af8eefa42a42c8b33611113ea35249",
            "max": 231508,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_cf9ba2291a244c4093c1f273713fb79c",
            "value": 231508
          }
        },
        "2b90461880434a16810d43371ab74d7d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b07a8c8d54d84aa0ac62937d1b7a61f7",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_049fd3969b0f4686ae97ff758f3c4ab1",
            "value": "‚Äá232k/232k‚Äá[00:00&lt;00:00,‚Äá2.26MB/s]"
          }
        },
        "38850d36cb844a47806befde98124188": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "55ac5a96ff4b465586d8dfc9d027cbb5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "99f1ff61bf9946a9b51ca9591de9aa0f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c0af8eefa42a42c8b33611113ea35249": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cf9ba2291a244c4093c1f273713fb79c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b07a8c8d54d84aa0ac62937d1b7a61f7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "049fd3969b0f4686ae97ff758f3c4ab1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "723b35fbf5f8408f827723f7ff717e80": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_275a9ee0148048b6bb93c9770ad6bb81",
              "IPY_MODEL_489357fa807d4bb1b45eec65c2dc238c",
              "IPY_MODEL_56395941c10b422fb9f230b57b5dd5db"
            ],
            "layout": "IPY_MODEL_6c4c1cf9548a4051a0fe503453810de9"
          }
        },
        "275a9ee0148048b6bb93c9770ad6bb81": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5e8d44e69cba47259296135c1b8a717a",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_9509f353876244ed9ff29b08de13e3e0",
            "value": "tokenizer.json:‚Äá100%"
          }
        },
        "489357fa807d4bb1b45eec65c2dc238c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7ec3287674434d639e63cc463efbcaae",
            "max": 711396,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_fab83ed6831640d3bf6edbd0ce912192",
            "value": 711396
          }
        },
        "56395941c10b422fb9f230b57b5dd5db": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_56fa2e2dcfce4f23b59b187d45cca6fc",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_56ba07e08bdf49959ee2f8252c7916f3",
            "value": "‚Äá711k/711k‚Äá[00:00&lt;00:00,‚Äá10.1MB/s]"
          }
        },
        "6c4c1cf9548a4051a0fe503453810de9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5e8d44e69cba47259296135c1b8a717a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9509f353876244ed9ff29b08de13e3e0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7ec3287674434d639e63cc463efbcaae": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fab83ed6831640d3bf6edbd0ce912192": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "56fa2e2dcfce4f23b59b187d45cca6fc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "56ba07e08bdf49959ee2f8252c7916f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e0df303e08c3419585c283cbe6102e3a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_60708fd0dd1445d3bbcef145ab292109",
              "IPY_MODEL_fc270dbb7c534e7f965c7f6f5e70db5a",
              "IPY_MODEL_e04bd3bdc986428dad7ca52525bdce8f"
            ],
            "layout": "IPY_MODEL_599d8e1cd5f9418cbfb6a8607245ff7a"
          }
        },
        "60708fd0dd1445d3bbcef145ab292109": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3872b985c94c4635baa49f8417885a1d",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_d05588e6e2a3468e8f62e805f51de794",
            "value": "special_tokens_map.json:‚Äá100%"
          }
        },
        "fc270dbb7c534e7f965c7f6f5e70db5a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a4402872bffb45958f0293bcbf2fadf6",
            "max": 695,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_80209095b1cd45899d0638a402003f5c",
            "value": 695
          }
        },
        "e04bd3bdc986428dad7ca52525bdce8f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cbd5b511e1764de58a72adefff495597",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_852f3b2f24b345a2b97097a2fa161118",
            "value": "‚Äá695/695‚Äá[00:00&lt;00:00,‚Äá32.6kB/s]"
          }
        },
        "599d8e1cd5f9418cbfb6a8607245ff7a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3872b985c94c4635baa49f8417885a1d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d05588e6e2a3468e8f62e805f51de794": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a4402872bffb45958f0293bcbf2fadf6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "80209095b1cd45899d0638a402003f5c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "cbd5b511e1764de58a72adefff495597": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "852f3b2f24b345a2b97097a2fa161118": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e6c00d601fe6485eb9ec3bc7979a203d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e6839ef953bd42d7933199cdd700c48a",
              "IPY_MODEL_40a0c4d28dfd43afabf6fb731b3c0e4a",
              "IPY_MODEL_42c1774d9dc64ce98ff92feb0e80921f"
            ],
            "layout": "IPY_MODEL_f279248232e54f9784ac4e8d0b742625"
          }
        },
        "e6839ef953bd42d7933199cdd700c48a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a2eb5335f5604dfd9aaa990baf46f686",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_5424c172838e4c7ba8021cbe6efe4891",
            "value": "config.json:‚Äá100%"
          }
        },
        "40a0c4d28dfd43afabf6fb731b3c0e4a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6ac7cef1125142a8bbe006964bb40f85",
            "max": 2064,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f6ef13ad79ed430fbe7f34a18522d904",
            "value": 2064
          }
        },
        "42c1774d9dc64ce98ff92feb0e80921f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0cb153759ac14c5ebaaa7198edf9dc2d",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_e32dd6f485dc44eea360d07302c60942",
            "value": "‚Äá2.06k/2.06k‚Äá[00:00&lt;00:00,‚Äá51.9kB/s]"
          }
        },
        "f279248232e54f9784ac4e8d0b742625": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a2eb5335f5604dfd9aaa990baf46f686": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5424c172838e4c7ba8021cbe6efe4891": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6ac7cef1125142a8bbe006964bb40f85": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f6ef13ad79ed430fbe7f34a18522d904": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0cb153759ac14c5ebaaa7198edf9dc2d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e32dd6f485dc44eea360d07302c60942": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ac32288ea9e1455c9f2bcdde79ddef2a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d5a0cf77dd9649ad8048120e7524e62a",
              "IPY_MODEL_b09f85e6dd8648c698936cd2113a8f72",
              "IPY_MODEL_1cac8cd1a8c24625af1036838afc95ab"
            ],
            "layout": "IPY_MODEL_f789b097889049f5bd343c6a4f6022ee"
          }
        },
        "d5a0cf77dd9649ad8048120e7524e62a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_de4bc84f73744ca3bd7b9986250b2875",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_cd7a84569d34411883a48b820f19d63a",
            "value": "configuration_hf_nomic_bert.py:‚Äá100%"
          }
        },
        "b09f85e6dd8648c698936cd2113a8f72": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_da5fd396c4b44ca0800769b2fd35def9",
            "max": 1958,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5cba8942e028470289d2709ee576c41c",
            "value": 1958
          }
        },
        "1cac8cd1a8c24625af1036838afc95ab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_30e5387606914080a99108c0415ae47d",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_78873e29fd004afa9ac1aab4feb68036",
            "value": "‚Äá1.96k/1.96k‚Äá[00:00&lt;00:00,‚Äá24.5kB/s]"
          }
        },
        "f789b097889049f5bd343c6a4f6022ee": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "de4bc84f73744ca3bd7b9986250b2875": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cd7a84569d34411883a48b820f19d63a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "da5fd396c4b44ca0800769b2fd35def9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5cba8942e028470289d2709ee576c41c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "30e5387606914080a99108c0415ae47d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "78873e29fd004afa9ac1aab4feb68036": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "da65d5ee14c74e4497cb27844dd5ac5d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d8a6881236b244d6bbdd711035d05e1f",
              "IPY_MODEL_d09bf2587e594473b50c4c02d574025d",
              "IPY_MODEL_6781797081a64b47a675e49fadf69367"
            ],
            "layout": "IPY_MODEL_4f016fe358ce462fb3f8fc3d6cf97704"
          }
        },
        "d8a6881236b244d6bbdd711035d05e1f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_17e8f231cc6f441a89efb913de2918cb",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_ef8acf34f1c14f6790ed7d3c6542a871",
            "value": "modeling_hf_nomic_bert.py:‚Äá100%"
          }
        },
        "d09bf2587e594473b50c4c02d574025d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c5c5223cf8374f27be702ae75c48024a",
            "max": 103563,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_693b05a975ed482e9cf86aa5d11f994a",
            "value": 103563
          }
        },
        "6781797081a64b47a675e49fadf69367": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c2b0f498fa9148bf9e479bb71475d5e7",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_4964fb23752e4785b6d9b8701bca3a57",
            "value": "‚Äá104k/104k‚Äá[00:00&lt;00:00,‚Äá6.98MB/s]"
          }
        },
        "4f016fe358ce462fb3f8fc3d6cf97704": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "17e8f231cc6f441a89efb913de2918cb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ef8acf34f1c14f6790ed7d3c6542a871": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c5c5223cf8374f27be702ae75c48024a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "693b05a975ed482e9cf86aa5d11f994a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c2b0f498fa9148bf9e479bb71475d5e7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4964fb23752e4785b6d9b8701bca3a57": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5ea80592d94d4cc1aff4fc20c53159b6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_22806a7a0333486ca39e7866752dec2e",
              "IPY_MODEL_4df41647825541fc967d6502d90ad635",
              "IPY_MODEL_b34ae6bea32b420bbe984f55c3f58775"
            ],
            "layout": "IPY_MODEL_bea8f085e9c9425184ae4d78c7e70d06"
          }
        },
        "22806a7a0333486ca39e7866752dec2e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4e701799129f43158f0832d7e65a5f76",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_8d01f84dc17c438c84741c1ddf439e45",
            "value": "model.safetensors:‚Äá100%"
          }
        },
        "4df41647825541fc967d6502d90ad635": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6da7ca01d9d9464fb9cc956bad1854e1",
            "max": 546938168,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3788a9c791464504bedf5bc5144b8c38",
            "value": 546938168
          }
        },
        "b34ae6bea32b420bbe984f55c3f58775": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7a352ef7d78c47f2bffd377ab08c747b",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_bbc32b356aec4319a35a281b54a8f7df",
            "value": "‚Äá547M/547M‚Äá[00:05&lt;00:00,‚Äá106MB/s]"
          }
        },
        "bea8f085e9c9425184ae4d78c7e70d06": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4e701799129f43158f0832d7e65a5f76": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8d01f84dc17c438c84741c1ddf439e45": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6da7ca01d9d9464fb9cc956bad1854e1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3788a9c791464504bedf5bc5144b8c38": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7a352ef7d78c47f2bffd377ab08c747b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bbc32b356aec4319a35a281b54a8f7df": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}