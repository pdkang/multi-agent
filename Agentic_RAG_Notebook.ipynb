{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hamzafarooq/multi-agent-course/blob/main/Module_1/Agentic_RAG/Agentic_RAG_Notebook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Deep Dive Agentic Retrieval Augmented Generation\n",
        "\n",
        "An Agentic RAG is required when we use reasoning to determine which action(s) to take and in which order to take them. Essentially we use agents instead of a LLM directly to accomplish a set of tasks which requires planning, multi step reasoning, tool use and/or learning over time. Agents give us agency!\n",
        "\n",
        "Agency : The ability to take action or to choose what action to take\n",
        "\n",
        "In the context of RAG, we can plug in agents to enhance the reasoning prior to selection of RAG pipelines, within a RAG pipeline for retrieval or reranking and finally for synthesising before we send out the response. This improves RAG to a large extent by automating complex workflows and decisions that are required for a non trivial RAG use case.\n",
        "\n",
        "### Purpose of this Agentic RAG\n",
        "This notebook presents a practical implementation of Agentic Retrieval-Augmented Generation (RAG)—a system where decision-making and tool selection are delegated to an intelligent agent before executing a response. Rather than passing every query through a static RAG pipeline, this system introduces agency—the ability to choose the best course of action depending on the nature of the query.\n",
        "\n",
        "At the heart of this implementation is a router prompt, which classifies user queries into one of three categories:\n",
        "\n",
        "- OpenAI documentation: Queries related to tools, APIs, or usage guidelines for OpenAI models\n",
        "- 10-K financial reports: Questions requiring retrieval from company filings or financial datasets\n",
        "- Live Internet search: Broader, current, or comparative queries that need web access\n",
        "\n",
        "Once the query is classified, the system invokes a corresponding route handler:\n",
        "\n",
        "- For OpenAI and 10-K queries, it retrieves relevant context from a vector database (Qdrant) using text embeddings, then applies a RAG-based response generator.\n",
        "- For Internet queries, it fetches real-time information using a web-access API (ARES).\n",
        "\n",
        "This approach is an example of Agentic RAG, where reasoning precedes retrieval and generation. By plugging in agents before and within the RAG pipeline, we make the system smarter and more adaptive. This allows us to:\n",
        "\n",
        "- Automatically choose the right retrieval method based on context\n",
        "- Combine structured knowledge with real-time search\n",
        "- Scale RAG beyond trivial use cases by integrating multi-step decision logic\n",
        "\n",
        "Importantly, no external agentic frameworks are used—this is a ground-up implementation that demonstrates how to build a lightweight but intelligent agentic system using only a language model, prompt engineering, and retrieval tools."
      ],
      "metadata": {
        "id": "mJ9XHTOPUCav"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setup and Dependencies"
      ],
      "metadata": {
        "id": "haelye0PUbdX"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "HciDI6OpSKJN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0c397241-7fdd-48de-a5cd-a66e4f9659ae"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/327.7 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m327.7/327.7 kB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/7.7 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.3/7.7 MB\u001b[0m \u001b[31m129.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m7.7/7.7 MB\u001b[0m \u001b[31m150.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.7/7.7 MB\u001b[0m \u001b[31m95.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m647.0/647.0 kB\u001b[0m \u001b[31m36.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m60.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "# Install the necessary libraries\n",
        "!pip install openai qdrant_client transformers pydantic==2.11.4 litellm --quiet"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json                 # For parsing and structuring JSON data (especially OpenAI and routing responses)\n",
        "\n",
        "# Google Colab-specific (for securely handling API keys)\n",
        "from google.colab import userdata  # To securely store and retrieve credentials in Colab\n",
        "\n",
        "# OS operations\n",
        "import os                   # Useful for accessing environment variables and managing paths\n",
        "\n",
        "# Embedding models (used for text vectorization during retrieval)\n",
        "from transformers import AutoTokenizer, AutoModel  # For loading custom transformer models if not using OpenAI embeddings\n",
        "\n",
        "# Vector database client\n",
        "from qdrant_client import AsyncQdrantClient  # Qdrant is used as the vector store to retrieve documents based on similarity\n",
        "\n",
        "import litellm\n",
        "import asyncio\n",
        "import datetime\n",
        "import asyncio\n",
        "\n",
        "from IPython.display import display, Markdown"
      ],
      "metadata": {
        "id": "J7xIyE7iyI63"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Defining the Internet Tool\n",
        "\n",
        "First, we will define a tool function that enables our system to answer queries requiring real-time, internet-based information. Not all questions can be answered using static documents like OpenAI docs or financial filings—sometimes users ask about current trends, comparisons, or live updates.\n",
        "\n",
        "To handle this, we introduce a live search capability using the **ARES API** by Traversaal.\n",
        "\n",
        "### What is ARES API?  \n",
        "ARES is a web-based tool that allows you to:\n",
        "\n",
        "- Search the internet in real time.\n",
        "- Get LLM-generated answers based on live search results.\n",
        "\n",
        "This is particularly useful for questions about:\n",
        "\n",
        "- Current events (e.g., *“Latest AI tools in 2025”*),\n",
        "- Tech comparisons (e.g., *“Gemini vs GPT-4”*),\n",
        "- General knowledge outside internal datasets.\n",
        "\n",
        "Please generate the API key [here](https://api.traversaal.ai)\n"
      ],
      "metadata": {
        "id": "JE6Bf6r19qhn"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1PydVhqpW43B"
      },
      "outputs": [],
      "source": [
        "#loads ares api key from colab secrets\n",
        "ares_api_key=userdata.get('ARES_API_KEY')\n",
        "OPENAI_API_KEY = userdata.get('OPENAI_API_KEY')\n",
        "\n",
        "# Required for litellm\n",
        "os.environ[\"OPENAI_API_KEY\"] = OPENAI_API_KEY"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6tF67DJgZ_sz"
      },
      "outputs": [],
      "source": [
        "import httpx # For sending HTTP POST requests to the ARES API\n",
        "\n",
        "async def get_internet_content(user_query: str, action: str):\n",
        "    \"\"\"\n",
        "    Fetches a response from the internet using ARES-API based on the user's query.\n",
        "\n",
        "    This function serves as the tool invoked when the router classifies a query\n",
        "    as requiring real-time information beyond internal datasets—i.e., \"INTERNET_QUERY\".\n",
        "    It sends the query to a live search API (ARES) and returns the result.\n",
        "\n",
        "    Args:\n",
        "        user_query (str): The user's question that needs a live answer.\n",
        "        action (str): Route type (always expected to be \"INTERNET_QUERY\").\n",
        "\n",
        "    Returns:\n",
        "        str: Response text generated using internet search or an error message.\n",
        "    \"\"\"\n",
        "    print(\"Getting your response from the internet 🌐 ...\")\n",
        "\n",
        "    # API endpoint for the ARES live search tool\n",
        "    url = \"https://api-ares.traversaal.ai/live/predict\"\n",
        "\n",
        "    # Payload structure expected by the ARES API\n",
        "    payload = {\"query\": [user_query]}\n",
        "\n",
        "    # Authentication and content headers for API access\n",
        "    headers = {\n",
        "        \"x-api-key\": ares_api_key,  # Your secret API key (should be securely loaded from environment)\n",
        "        \"content-type\": \"application/json\"\n",
        "    }\n",
        "    custom_timeout = httpx.Timeout(10.0, read=30.0) # 10s connect, 30s read\n",
        "    try:\n",
        "        async with httpx.AsyncClient(timeout=custom_timeout) as client:\n",
        "            response = await client.post(url, json=payload, headers=headers)\n",
        "            response.raise_for_status()\n",
        "        return response.json().get('data', {}).get('response_text', \"No response received.\")\n",
        "\n",
        "    # Handle HTTP-level errors (e.g., 400s or 500s)\n",
        "    except httpx.HTTPStatusError as http_err:\n",
        "        return f\"HTTP error occurred: {http_err}\"\n",
        "\n",
        "    # Handle general connection, timeout, or request formatting issues\n",
        "    except httpx.RequestError as req_err:\n",
        "        print(req_err)\n",
        "        return f\"Request error occurred: {req_err}\"\n",
        "\n",
        "    # Catch-all for any unexpected failure\n",
        "    except Exception as err:\n",
        "        return f\"An unexpected error occurred: {err}\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "USRVlUIVaRGM",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 526
        },
        "outputId": "ef7c32c9-a788-4c55-ccf6-f0732e2cdb1e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Getting your response from the internet 🌐 ...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "Here are some of the best travel destinations for 2025:\n\n1. **Budapest, Hungary** - Known for its rich history and stunning architecture, Budapest offers a vibrant cultural experience.\n2. **Bukhara, Uzbekistan** - A city steeped in history, Bukhara is famous for its well-preserved medieval architecture and cultural heritage.\n3. **Charleston, South Carolina, USA** - Renowned for its charming streets, historic homes, and Southern hospitality, Charleston is a top destination for cultural immersion.\n4. **Inverness and the Flow Country, Scotland** - This area is perfect for nature lovers, offering breathtaking landscapes and a chance to explore Scottish culture.\n5. **Seoul, South Korea** - A bustling metropolis that blends modernity with tradition, Seoul is a top pick for solo travelers.\n6. **Kathmandu, Nepal** - Known for its rich culture and proximity to the Himalayas, Kathmandu is a great destination for adventure seekers.\n7. **Cusco, Peru** - The gateway to Machu Picchu, Cusco is rich in Incan history and offers stunning landscapes.\n8. **Bangkok, Thailand** - A vibrant city known for its street food, temples, and bustling markets.\n9. **Osaka, Japan** - Famous for its modern architecture, nightlife, and delicious cuisine.\n10. **Dubai, UAE** - A city known for luxury shopping, ultramodern architecture, and a lively nightlife scene.\n11. **Mauritius** - An island nation known for its beautiful beaches and diverse culture.\n12. **Bali, Indonesia** - Famous for its stunning beaches, vibrant culture, and wellness retreats.\n13. **Maldives** - Known for its crystal-clear waters and luxurious resorts, perfect for relaxation.\n14. **Hoi An, Vietnam** - A well-preserved ancient town known for its beautiful architecture and rich history.\n15. **Phuket, Thailand** - A popular island destination known for its beaches and vibrant nightlife.\n16. **Santorini, Greece** - Famous for its stunning sunsets, white-washed buildings, and beautiful beaches.\n17. **Zanzibar, Tanzania** - Known for its beautiful beaches and rich cultural heritage.\n18. **Dominica** - An island known for its natural beauty, including rainforests and hot springs.\n19. **Naoshima, Japan** - An island dedicated to contemporary art, featuring museums and installations.\n20. **The Dolomites, Italy** - A mountain range known for its stunning scenery and outdoor activities.\n21. **Greenland** - Offers breathtaking landscapes and unique cultural experiences.\n22. **Wales** - Known for its stunning landscapes, castles, and rich history.\n\nThese destinations offer a mix of cultural experiences, natural beauty, and adventure, making them ideal for travelers in 2025."
          },
          "metadata": {}
        }
      ],
      "source": [
        "display(Markdown(await get_internet_content(\"Tell me about best travel destinations in 2025?\",\"INTERNET_QUERY\"))) #run internet function to test results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ocV_ALVEaRi0"
      },
      "source": [
        "## 2. Router Query Function — Giving the Agent Its Brain\n",
        "\n",
        "In this step, we will define the router function, which plays a critical role in our Agentic RAG system.\n",
        "\n",
        "### What is a Router?\n",
        "\n",
        "A router is like the decision-making brain of our assistant.\n",
        "\n",
        "Before trying to answer a user's question, the system first needs to figure out:\n",
        "\n",
        "> “Where should I go to find the right answer?”\n",
        "\n",
        "To make this decision, we use the OpenAI GPT model. We provide it with a detailed system prompt that explains how to classify the user's question into one of these categories:\n",
        "\n",
        "- **OPENAI_QUERY** → Questions about OpenAI tools, APIs, models, or documentation.\n",
        "- **10K_DOCUMENT_QUERY** → Questions about companies, financial filings, or analysis based on 10-K reports.\n",
        "- **INTERNET_QUERY** → Anything else that likely requires real-time or general web information.\n",
        "\n",
        "### What does the function do?\n",
        "\n",
        "- Sends the user's question to the OpenAI API.\n",
        "- Receives a JSON response containing:\n",
        "  - `action`: The category the query belongs to.\n",
        "  - `reason`: A short explanation for the decision.\n",
        "  - `answer`: (Optional) A quick response if it’s simple enough (left blank for internet queries).\n",
        "- Parses the response and returns it as a Python dictionary.\n",
        "\n",
        "### Why is this important?\n",
        "\n",
        "This router gives the system agency—the ability to decide which knowledge source to use. It’s what makes this pipeline agentic, not just static.\n",
        "\n",
        "Without the router, every query would follow the same path. With it, we can:\n",
        "\n",
        "- Dynamically switch between tools and data sources.\n",
        "- Handle different types of user questions intelligently.\n",
        "- Avoid wasting resources on unnecessary steps.\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from openai import OpenAIError\n",
        "from pydantic import BaseModel, Field\n",
        "from typing import List, Literal\n",
        "\n",
        "class Actions(BaseModel):\n",
        "    action: Literal[\"OPENAI_QUERY\", \"10K_DOCUMENT_QUERY\", \"INTERNET_QUERY\"] = Field(description=\"The action to take\")\n",
        "    reason: str = Field(description=\"The reason for the action\")\n",
        "    answer: str = Field(description=\"The answer to the question\")\n",
        "\n",
        "async def route_query(user_query: str):\n",
        "    router_system_prompt =f\"\"\"\n",
        "    As a professional query router, your objective is to correctly classify user input into one of three categories based on the source most relevant for answering the query:\n",
        "\n",
        "    1. OPENAI_QUERY:\n",
        "        - If the user's query appears to be answerable using information from OpenAI's official documentation, tools, models, APIs, or services (e.g., GPT, ChatGPT, embeddings, moderation API, usage guidelines).\n",
        "        - Questions that can likely be answered by consulting official OpenAI resources.\n",
        "\n",
        "    2. 10K_DOCUMENT_QUERY:\n",
        "        - Assign this category if the query is specifically asking for information found within, or analysis based upon, 10-K annual reports, company financial filings, or other structured financial/company datasets.\n",
        "        - Information directly retrievable or analyzable from structured corporate/financial documents, particularly 10-K reports.\n",
        "        - Assume past data is present here.\n",
        "\n",
        "    3. INTERNET_QUERY:\n",
        "        - If the query is neither related to OpenAI nor the 10k documents specifically, or if the information might require a broader search (e.g., news, trends, tools outside these platforms), route it here.\n",
        "        - If unsure, or if the query is very broad, lean towards INTERNET_QUERY.\n",
        "\n",
        "    Your decision should be made by assessing the domain of the query.\n",
        "\n",
        "    EXAMPLES:\n",
        "    - User: How to fine-tune GPT-3?\n",
        "        Response:\n",
        "            reason: Fine-tuning is OpenAI-specific\n",
        "            action: OPENAI_QUERY\n",
        "            answer: Use fine-tuning API\n",
        "\n",
        "    - User: Where can I find the latest financial reports for the last 10 years?\n",
        "        Response:\n",
        "            reason: Query related to annual reports\n",
        "            action: 10K_DOCUMENT_QUERY\n",
        "            answer: Access through document database\n",
        "\n",
        "\n",
        "    - User: Top leadership styles in 2024\n",
        "        Response:\n",
        "            reason: Needs current leadership trends,\n",
        "            action: INTERNET_QUERY\n",
        "            answer: \"\"\n",
        "\n",
        "\n",
        "    - User: What's the difference between ChatGPT and Claude?\n",
        "        Response:\n",
        "            reason: Cross-comparison of different providers\n",
        "            action: INTERNET_QUERY\n",
        "            answer: \"\"\n",
        "\n",
        "    Strictly follow this format for every query, and never deviate.\n",
        "\n",
        "    Current datetime is : {datetime.datetime.now()}, always consider this when making decisions.\n",
        "    \"\"\"\n",
        "\n",
        "    try:\n",
        "        # Query the GPT-4 model with the router prompt and user input\n",
        "        response = await litellm.acompletion(\n",
        "            model=\"gpt-4o\",\n",
        "            messages=[{\"role\": \"system\", \"content\": router_system_prompt},\n",
        "                      {\"role\":\"user\",\"content\":user_query}],\n",
        "            response_format=Actions,\n",
        "            temperature=0.0,\n",
        "\n",
        "        )\n",
        "\n",
        "\n",
        "        # Extract and parse the model's JSON response\n",
        "        json_response = response.choices[0].message.content\n",
        "        parsed_response = Actions.model_validate_json(json_response)\n",
        "        return parsed_response\n",
        "\n",
        "    # Handle OpenAI API errors (e.g., rate limits, authentication)\n",
        "    except OpenAIError as api_err:\n",
        "        return {\n",
        "            \"action\": \"INTERNET_QUERY\",\n",
        "            \"reason\": f\"OpenAI API error: {api_err}\",\n",
        "            \"answer\": \"\"\n",
        "        }\n",
        "\n",
        "    # Handle case where model response isn't valid JSON\n",
        "    except json.JSONDecodeError as json_err:\n",
        "        return {\n",
        "            \"action\": \"INTERNET_QUERY\",\n",
        "            \"reason\": f\"JSON parsing error: {json_err}\",\n",
        "            \"answer\": \"\"\n",
        "        }\n",
        "\n",
        "    # Catch-all for any other unforeseen issues\n",
        "    except Exception as err:\n",
        "        return {\n",
        "            \"action\": \"INTERNET_QUERY\",\n",
        "            \"reason\": f\"Unexpected error: {err}\",\n",
        "            \"answer\": \"\"\n",
        "        }"
      ],
      "metadata": {
        "id": "5bBt3L8qijeb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "await route_query(\"what is the revenue of uber in 2021?\")"
      ],
      "metadata": {
        "id": "5ilSsVBBv-KT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cd7a3364-4c91-40d8-e3c2-ef83f8c04843"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Actions(action='10K_DOCUMENT_QUERY', reason=\"The query is asking for specific financial data from a company's annual report.\", answer=\"Check Uber's 2021 10-K report for revenue details.\")"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VrkE-V4PlClH"
      },
      "source": [
        "## 3. Setting Up Qdrant Vector Database for Agentic RAG\n",
        "In this step, we are connecting our agent to a pre-built vector database using Qdrant—a tool used to store and search document embeddings (numerical representations of text).\n",
        "\n",
        "What Are We Doing?\n",
        "We are loading an existing Qdrant database that was downloaded from a GitHub repository. This database already contains:\n",
        "\n",
        "- Vectorized OpenAI documentation\n",
        "- Vectorized 10-K financial filings\n",
        "\n",
        "By loading this saved data:\n",
        "\n",
        "- We save time (no need to re-embed the documents)\n",
        "- We enable fast similarity search to retrieve relevant text chunks\n",
        "\n",
        "This setup allows our system to perform semantic search, meaning it can understand the meaning of the user query and match it with the most relevant pieces of information stored in the database.\n",
        "\n",
        "\n",
        "### Why This Matters in Agentic RAG\n",
        "Once the router decides that the query should go to the OpenAI docs or the 10-K reports, our system uses Qdrant to:\n",
        "\n",
        "- Search for the most relevant pieces of text\n",
        "- Pass those to the model to generate a grounded answer\n",
        "\n",
        "So, this step is essential to support retrieval-augmented generation (RAG) within our agentic flow."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Data Sources:\n",
        "\n",
        "**10K Database: Lyft 2024 & Uber 2021 SEC filings**\n",
        "\n",
        "**OpenAI Docs: Official OpenAI documentation**\n",
        "\n",
        "For lecture demo purposes, the vecitr database has already been created and hosted on Github which we will clone here. In order to create your own embeddings, the notebook and data will be hosted and shared on github"
      ],
      "metadata": {
        "id": "yXAXLB2eCgSn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Clone the project repository that contains prebuilt vector data (e.g., Qdrant collections)\n",
        "# This includes document embeddings and configurations needed for retrieval (10-K, OpenAI docs)\n",
        "!git clone https://github.com/hamzafarooq/multi-agent-course.git --quiet\n"
      ],
      "metadata": {
        "id": "suqlk9P9YJfQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 🗄️ Initializing Qdrant client with local path to vector database\n",
        "# The path points to prebuilt Qdrant collections (10-K and OpenAI docs) cloned from the repository\n",
        "# This enables fast, local retrieval of relevant document chunks based on semantic similarity\n",
        "if 'client' in globals():\n",
        "    # Delete existing client if it exists\n",
        "    del client\n",
        "    print(\"Deleted existing Qdrant client\")\n",
        "\n",
        "client = AsyncQdrantClient(path=\"/content/multi-agent-course/Module_1/Agentic_RAG/qdrant_data\")\n"
      ],
      "metadata": {
        "id": "BB-p1nzYo91-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z90HaV0jm93H"
      },
      "source": [
        "## 4. Building the Retriever and RAG for Vector Databases\n",
        "In this section, we build the core logic that allows our agent to find relevant documents and generate grounded answers using them.\n",
        "\n",
        "###Step 1: Import the Embedding Model\n",
        "We start by importing the nomic-ai/nomic-embed-text-v1.5 model from Hugging Face. This model is used to convert any text (such as a user query) into a dense vector, known as an embedding. These embeddings capture the semantic meaning of text, allowing us to later compare and retrieve similar documents.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qM6mDo0InEji",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 467,
          "referenced_widgets": [
            "1bab9a14081841bdb36625f4a98a36d7",
            "ee98662d3e954463908bebf5e9a3f9dd",
            "a2fab8920327413e8f1a9d4e636003c7",
            "bf72c3e67d21431b8425d0e1fbd52ffb",
            "cdff734ffbbe40a3b12126a8bdd834e0",
            "7ef64ffcbcd34270b7862fdcc68b99ae",
            "25e8ec5de5db40a09816f1d69bd7fba6",
            "9b8e16ccb6c64a799866181ee14dcafc",
            "0e802fdaddd944929558e6796a1de701",
            "b6f993dce2414cacbb3c471bb6a3f14c",
            "f7f0bb0337d043b992ab77df8e8f1345",
            "852de2b2421f417abc20dc2d483c8d0c",
            "9d0a93c2c7d147a19dc39a1128161277",
            "7963cc544dec4beb981907da069ca2bc",
            "adc78f8e66a14b76b38b9be63fa83a33",
            "d8d002f7161944bbb79014ea1cac9acd",
            "59ea57f4c24f43769fd10135b409a9aa",
            "8bff07949b004dfda01aa6255a0deefa",
            "5c01d1aec339408297a633c34990603d",
            "e3302658450047c592b04e4859d3d5e9",
            "3970aa19967d4e0a88afd91b8da5153b",
            "271308838afd45bc8b5e91ca2e86c106",
            "8fb0ad2ea6f042fda8db65992087f995",
            "24c7e03b975f4e2ca81662d1908a70de",
            "1953ea27661d4f8d9eaee29bbd8fa6a2",
            "fc364d1578b34fbdb847fd40cb41a67b",
            "01d488d6abb346b8994b54b9e18f6a1a",
            "ce30a52b628a452f994f481115385c9c",
            "4a1677480b90499c89276cad462b023c",
            "af684197bd7c45369fca9c5f1a9377b6",
            "1c4403779e21403f99d72d6b7a91ed53",
            "b7694849e5c1497f99a700229c688749",
            "0817f56372244726bfde7cae38194c73",
            "3414c4b6ecf048f1a8030e1ea8e075d4",
            "ff6c63fd177745148944fe8479857972",
            "744fefcc324346cea04095ef9122aa46",
            "e255db904b4247b79e3fec6bf550a4b2",
            "97b45b217dd74ac1989f7db8914fbcf6",
            "527aab6bd18d444ba442a00bcd8090cc",
            "91d3978d47dc427ca431050da101f6a1",
            "cb29e12b30dc43f8aaa3f707236ba7e8",
            "58af76d7d4a24ff7bdf07f50d3bd42ca",
            "3ccc2952581349cd8f066f6187b4effe",
            "86558585c8c242daad91f2729100f1d6",
            "34a67b3b09fd4f24bfc2cf635c5fd852",
            "0c5976ac90c54b8ca68034802d633832",
            "38b018b5205f4c23b8c223ba41ebd6eb",
            "61201ab60bda48059162ef9815bf2aef",
            "2201fa8b923c438996ed9aa94b272da9",
            "12d7982bd9de41549b2a1ec7fe1e8e1a",
            "b33b93d57490490b8485ac4b12afcb03",
            "da0a85d2f5d141d0af5b5ba0d0f20c53",
            "f4fa9826fb9b4c138d2037a3ce36327e",
            "bb9aadf46c96415b90d31ad26020bce1",
            "03e70543f8204b398783955e13cf0e77",
            "825626df03644486af945e8764c5fda9",
            "3cf7ae9822684589849fb2886e333227",
            "3461a55edeb34b5c91bb306569cb1749",
            "bae08a198ff842799930b4a1b13df99c",
            "ee5bc22efbb84673aee5ec8492e29eb8",
            "560848c05b974b09ab7636148cc8b525",
            "42fdaf5c1e0b48acbedf00be7ca823e7",
            "a81aebbc02c648d69df281d4eaadeb38",
            "06556cfe6f1c404aac5a5484e0c873c6",
            "37bea2c6d3864d4f881ec0cd530e40c1",
            "17a4352dda1e45f6b6d7aa933312a72c",
            "49856f0ba9e84168a1ce6db84350e494",
            "9ed8cb6071af4f1c93187754168bf084",
            "3a348823a00943d29dd8d0cc8d754510",
            "44779322c1414b5da87a17925bdf4b8a",
            "026b4ccdc0ea4412bf15991421c53eda",
            "84618bcc47044468b48760e39f9989a0",
            "700da68172fb4f0abf4295550bcff786",
            "aec654c0c87f452f8776cc7cbdda9896",
            "298495a138d847de939b9d6704019a3b",
            "09487a1614b048a2bafacda4a6822aca",
            "3786c23bf3a144f488e84d1d2ff0be2d",
            "37fe154b716a449fb36ffcd40370207d",
            "cc934572135b443380bfd6c53f355404",
            "81c42550c5734a9eb89399e046b1d8e5",
            "5f6cd961da72449cbda17bd4206d53bc",
            "01f4b890b42246df8ed267ce021af2d3",
            "093b7802140b4fa39fe82f27c977f06c",
            "0940a646cfca45deb2cc6726bf97178b",
            "2694714e016f478bbf85a764c44f785c",
            "f13c82e4ab924365b11f86d9bfab3d2d",
            "4044511a1906489b86157a8be5d8e5b3",
            "eae3b55fcab14a8590780a27723415ac"
          ]
        },
        "outputId": "6bdb643a-a4d0-4df6-d11a-9e10bb271c98"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/1.19k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1bab9a14081841bdb36625f4a98a36d7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "852de2b2421f417abc20dc2d483c8d0c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/711k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8fb0ad2ea6f042fda8db65992087f995"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/695 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3414c4b6ecf048f1a8030e1ea8e075d4"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/2.06k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "34a67b3b09fd4f24bfc2cf635c5fd852"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "configuration_hf_nomic_bert.py:   0%|          | 0.00/1.96k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "825626df03644486af945e8764c5fda9"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "A new version of the following files was downloaded from https://huggingface.co/nomic-ai/nomic-bert-2048:\n",
            "- configuration_hf_nomic_bert.py\n",
            ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "modeling_hf_nomic_bert.py:   0%|          | 0.00/104k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "49856f0ba9e84168a1ce6db84350e494"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "A new version of the following files was downloaded from https://huggingface.co/nomic-ai/nomic-bert-2048:\n",
            "- modeling_hf_nomic_bert.py\n",
            ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n",
            "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
            "WARNING:huggingface_hub.file_download:Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/547M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "37fe154b716a449fb36ffcd40370207d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:transformers_modules.nomic-ai.nomic-bert-2048.7710840340a098cfb869c4f65e87cf2b1b70caca.modeling_hf_nomic_bert:<All keys matched successfully>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ 1.2799692   0.40158355 -3.5162656  -0.3981321   1.5919138 ]\n"
          ]
        }
      ],
      "source": [
        "# Load the tokenizer and embedding model from Hugging Face\n",
        "# This model converts raw text into dense vector representations (embeddings)\n",
        "# Used for similarity search in Qdrant during document retrieval\n",
        "text_tokenizer = AutoTokenizer.from_pretrained(\"nomic-ai/nomic-embed-text-v1.5\", trust_remote_code=True)\n",
        "text_model = AutoModel.from_pretrained(\"nomic-ai/nomic-embed-text-v1.5\", trust_remote_code=True)\n",
        "\n",
        "def get_text_embeddings(text):\n",
        "    \"\"\"\n",
        "    Converts input text into a dense embedding using the Nomic embedding model.\n",
        "    These embeddings are used to query Qdrant for semantically relevant document chunks.\n",
        "\n",
        "    Args:\n",
        "        text (str): The input text or query from the user.\n",
        "\n",
        "    Returns:\n",
        "        np.ndarray: A fixed-size vector representing the semantic meaning of the input.\n",
        "    \"\"\"\n",
        "    # Tokenize and prepare input for the model\n",
        "    inputs = text_tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True)\n",
        "\n",
        "    # Forward pass to get model outputs\n",
        "    outputs = text_model(**inputs)\n",
        "\n",
        "    # Take the mean across all token embeddings to get a single vector (pooled representation)\n",
        "    embeddings = outputs.last_hidden_state.mean(dim=1)\n",
        "\n",
        "    # Convert to NumPy array and detach from computation graph\n",
        "    return embeddings[0].detach().numpy()\n",
        "\n",
        "# Example usage: Generate and preview the embedding of a test sentence\n",
        "text = \"This is a test sentence.\"\n",
        "embeddings = get_text_embeddings(text)\n",
        "print(embeddings[:5])  # Print first 5 dimensions for inspection\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 2: Define the Embedding Function\n",
        "We then define a function get_text_embeddings() which:\n",
        "\n",
        "- Tokenizes the input text\n",
        "- Runs it through the model\n",
        "- Computes the average of all token embeddings\n",
        "- Returns a single vector that represents the full sentence\n",
        "\n",
        "This vector will be used to query Qdrant to find the most relevant document chunks based on similarity."
      ],
      "metadata": {
        "id": "nXOx47EKw2ir"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "async def rag_formatted_response(user_query: str, context: list):\n",
        "    \"\"\"\n",
        "    Generate a response to the user query using the provided context,\n",
        "    with article references formatted as [1][2], etc.\n",
        "\n",
        "    This function performs the final step in the RAG pipeline—synthesizing an answer\n",
        "    from retrieved document chunks (context). It prompts the model to generate a\n",
        "    grounded response, explicitly citing sources using a reference format.\n",
        "\n",
        "    Args:\n",
        "        user_query (str): The user's original question.\n",
        "        context (list): List of text chunks retrieved from Qdrant (10-K or OpenAI docs).\n",
        "\n",
        "    Returns:\n",
        "        str: A generated response grounded in the retrieved context, with numbered citations.\n",
        "    \"\"\"\n",
        "\n",
        "    # Construct a RAG prompt that includes both:\n",
        "    # 1. The user's query\n",
        "    # 2. The supporting context documents\n",
        "    # The prompt instructs the model to answer using only the provided context,\n",
        "    # and to include citations like [1], [2], etc. based on chunk IDs or order.\n",
        "    rag_prompt = f\"\"\"\n",
        "       Based on the given context, answer the user query: {user_query}\\nContext:\\n{context}\n",
        "       and employ references to the ID of articles provided [ID], ensuring their relevance to the query.\n",
        "       The referencing should always be in the format of [1][2]... etc. </instructions>\n",
        "    \"\"\"\n",
        "\n",
        "    #  Call GPT-4o to generate the response using the RAG-style prompt\n",
        "    response = await litellm.acompletion(\n",
        "        model=\"gpt-4\",\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": rag_prompt},\n",
        "        ],\n",
        "        # temperature=0.0,\n",
        "    )\n",
        "\n",
        "    # Return the model's generated answer\n",
        "    return response.choices[0].message.content\n"
      ],
      "metadata": {
        "id": "3r6MeyRz8sv7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 3: Define the RAG Response Generator\n",
        "After retrieving relevant text chunks from Qdrant, we use the rag_formatted_response() function to generate a final answer. This function:\n",
        "\n",
        "- Takes the user query and the retrieved document chunks\n",
        "- Builds a prompt that asks the language model (GPT-4o) to answer the question using only the provided context\n",
        "- Instructs the model to include references like [1], [2] for traceability\n",
        "\n",
        "This ensures the output is not only informative but also grounded in actual retrieved data.\n",
        "\n",
        "Together, these two functions lay the foundation for combining retrieval (from vector DB) and generation (from LLM) — the two pillars of a RAG system.\n",
        "\n"
      ],
      "metadata": {
        "id": "zdaeGcoCDw5w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "async def retrieve_and_response(user_query: str, action: str):\n",
        "    \"\"\"\n",
        "    Retrieves relevant text chunks from the appropriate Qdrant collection\n",
        "    based on the query type, then generates a response using RAG.\n",
        "\n",
        "    This function powers the retrieval and response generation pipeline\n",
        "    for queries that are classified as either OPENAI-related or 10-K related.\n",
        "    It uses semantic search to fetch relevant context from a Qdrant vector store\n",
        "    and then generates a response using that context via a RAG prompt.\n",
        "\n",
        "    Args:\n",
        "        user_query (str): The user's input question.\n",
        "        action (str): The classification label from the router (e.g., \"OPENAI_QUERY\", \"10K_DOCUMENT_QUERY\").\n",
        "\n",
        "    Returns:\n",
        "        str: A model-generated response grounded in retrieved documents, or an error message.\n",
        "    \"\"\"\n",
        "\n",
        "    # Define mapping of routing labels to their respective Qdrant collections\n",
        "    collections = {\n",
        "        \"OPENAI_QUERY\": \"opnai_data\",           # Collection of OpenAI documentation embeddings\n",
        "        \"10K_DOCUMENT_QUERY\": \"10k_data\"        # Collection of 10-K financial document embeddings\n",
        "    }\n",
        "\n",
        "    try:\n",
        "        # Ensure that the provided action is valid\n",
        "        if action not in collections:\n",
        "            return \"Invalid action type for retrieval.\"\n",
        "\n",
        "        # Step 1: Convert the user query into a dense vector (embedding)\n",
        "        try:\n",
        "            query = get_text_embeddings(user_query)\n",
        "        except Exception as embed_err:\n",
        "            return f\"Embedding error: {embed_err}\"  # Fail early if embedding fails\n",
        "\n",
        "        # Step 2: Retrieve top-matching chunks from the relevant Qdrant collection\n",
        "        try:\n",
        "            text_hits = await client.query_points(\n",
        "                collection_name=collections[action],  # Choose the right collection based on routing\n",
        "                query=query,                          # The embedding of the user's query\n",
        "                limit=3                               # Fetch top 3 relevant chunks\n",
        "            )\n",
        "        except Exception as qdrant_err:\n",
        "            return f\"Vector DB query error: {qdrant_err}\"  # Handle Qdrant access issues\n",
        "\n",
        "        # Extract the raw content from the retrieved vector hits\n",
        "        contents = [point.payload['content'] for point in text_hits.points]\n",
        "\n",
        "        # If no relevant content is found, return early\n",
        "        if not contents:\n",
        "            return \"No relevant content found in the database.\"\n",
        "\n",
        "        # Step 3: Pass the retrieved context to the RAG model to generate a response\n",
        "        try:\n",
        "            response = await rag_formatted_response(user_query, contents)\n",
        "            return response\n",
        "        except Exception as rag_err:\n",
        "            return f\"RAG response error: {rag_err}\"  # Handle generation failures\n",
        "\n",
        "    # Catch any unforeseen errors in the overall process\n",
        "    except Exception as err:\n",
        "        return f\"Unexpected error: {err}\"\n"
      ],
      "metadata": {
        "id": "hp0y2J1AgX2t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5. Putting It All Together: Running the Agentic RAG\n",
        "In this final step, we combine everything into a single function that controls the entire Agentic RAG workflow. The agentic_rag() function acts as the main orchestrator of the system.\n",
        "\n",
        "Here’s what it does:\n",
        "\n",
        "- Prints the user's query for reference.\n",
        "- Uses the router function (powered by GPT) to decide which type of data source to use:\n",
        "  - OpenAI documentation\n",
        "  - 10-K financial reports\n",
        "- Internet search\n",
        "- Calls the correct function based on the route:\n",
        "- If it’s an OpenAI or 10-K query, it retrieves data from Qdrant and generates a RAG response.\n",
        "- If it’s an Internet query, it uses the ARES API to fetch live information.\n",
        "- Displays the final response, neatly formatted in the console.\n",
        "\n",
        "This step brings the agentic loop full circle—from understanding the question, reasoning about where to search, to finally responding with the best possible answer."
      ],
      "metadata": {
        "id": "yfYzErTYzhnK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dictionary that maps the route labels (decided by the router) to their respective functions\n",
        "# Each type of query is handled differently:\n",
        "# - OPENAI_QUERY and 10K_DOCUMENT_QUERY use document retrieval + RAG\n",
        "# - INTERNET_QUERY uses a web search API\n",
        "routes = {\n",
        "    \"OPENAI_QUERY\":  retrieve_and_response,\n",
        "    \"10K_DOCUMENT_QUERY\":  retrieve_and_response,\n",
        "    \"INTERNET_QUERY\": get_internet_content,\n",
        "}\n",
        "\n",
        "async def agentic_rag(user_query: str):\n",
        "    \"\"\"\n",
        "    Main function that runs the full Agentic RAG system.\n",
        "\n",
        "    This function takes a user's question, decides what type of query it is (OpenAI-related,\n",
        "    financial document-related, or general internet), and then calls the right function\n",
        "    to handle it. Finally, it prints out the full conversation and response.\n",
        "\n",
        "    Args:\n",
        "        user_query (str): The user's input question.\n",
        "\n",
        "    Returns:\n",
        "        None (It just prints the result nicely to the console)\n",
        "    \"\"\"\n",
        "\n",
        "    #  Terminal color codes to make the printed output easier to read and visually structured\n",
        "    CYAN = \"\\033[96m\"\n",
        "    GREY = \"\\033[90m\"\n",
        "    BOLD = \"\\033[1m\"\n",
        "    RESET = \"\\033[0m\"\n",
        "\n",
        "    try:\n",
        "        # Step 1: Print the user's original question to the console\n",
        "        print(f\"{BOLD}{CYAN}👤 User Query:{RESET} {user_query}\\n\")\n",
        "\n",
        "        # Step 2: Use the router (powered by GPT) to decide which route the query belongs to\n",
        "        try:\n",
        "            response = await route_query(user_query)\n",
        "        except Exception as route_err:\n",
        "            # If something goes wrong while classifying the query, show an error message\n",
        "            print(f\"{BOLD}{CYAN}🤖 BOT RESPONSE:{RESET}\\n\")\n",
        "            print(f\"Routing error: {route_err}\\n\")\n",
        "            return\n",
        "\n",
        "        # Extract the routing decision and the reason behind it\n",
        "        action = response.action  # e.g., \"OPENAI_QUERY\"\n",
        "        reason = response.reason  # e.g., \"Related to OpenAI tools\"\n",
        "\n",
        "        # Step 3: Show the selected route and why it was chosen\n",
        "        print(f\"{GREY}📍 Selected Route: {action}\")\n",
        "        print(f\"📝 Reason: {reason}\")\n",
        "        print(f\"⚙️ Processing query...{RESET}\\n\")\n",
        "\n",
        "        # Step 4: Call the correct function depending on the route (retrieval or web search)\n",
        "        try:\n",
        "            route_function = routes.get(action)  # Find the function to use for this route\n",
        "            if route_function:\n",
        "                result = await route_function(user_query, action)  # Run the function with the user's input\n",
        "            else:\n",
        "                result = f\"Unsupported action: {action}\"  # Catch unknown routing types\n",
        "        except Exception as exec_err:\n",
        "            result = f\"Execution error: {exec_err}\"  # Handle failure in the chosen route function\n",
        "\n",
        "        # Step 5: Print the final response to the user\n",
        "        print(f\"{BOLD}{CYAN}🤖 BOT RESPONSE:{RESET}\\n\")\n",
        "\n",
        "        #TODO: printing and return is inefficient\n",
        "        print(f\"{result}\\n\")\n",
        "        return f\"{result}\"\n",
        "\n",
        "    except Exception as err:\n",
        "        # Catch-all for any unexpected errors in the overall logic\n",
        "        print(f\"{BOLD}{CYAN}🤖 BOT RESPONSE:{RESET}\\n\")\n",
        "        print(f\"Unexpected error occurred: {err}\\n\")\n"
      ],
      "metadata": {
        "id": "ssG-BM9GpT-p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "display(Markdown(await agentic_rag(\"what was uber revenue in 2021?\")))"
      ],
      "metadata": {
        "id": "0-rTHJpGDTea",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 220
        },
        "outputId": "6c1c8571-108e-4052-ce8f-4ed0a640756a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m\u001b[96m👤 User Query:\u001b[0m what was uber revenue in 2021?\n",
            "\n",
            "\u001b[90m📍 Selected Route: 10K_DOCUMENT_QUERY\n",
            "📝 Reason: The query is asking for specific financial data from a company's annual report, which is typically found in 10-K filings.\n",
            "⚙️ Processing query...\u001b[0m\n",
            "\n",
            "\u001b[1m\u001b[96m🤖 BOT RESPONSE:\u001b[0m\n",
            "\n",
            "Uber's revenue in 2021 was $17,455 million [1].\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "Uber's revenue in 2021 was $17,455 million [1]."
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "display(Markdown(await agentic_rag(\"what was lyft revenue in 2024?\")))"
      ],
      "metadata": {
        "id": "TncVUsVpu3WC",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 220
        },
        "outputId": "c065453e-8d12-4a11-82bb-6d70a833e9b4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m\u001b[96m👤 User Query:\u001b[0m what was lyft revenue in 2024?\n",
            "\n",
            "\u001b[90m📍 Selected Route: 10K_DOCUMENT_QUERY\n",
            "📝 Reason: The query is asking for specific financial data from 2024, which would be found in a company's 10-K report.\n",
            "⚙️ Processing query...\u001b[0m\n",
            "\n",
            "\u001b[1m\u001b[96m🤖 BOT RESPONSE:\u001b[0m\n",
            "\n",
            "Lyft's revenue in 2024 was $5,786,016,000 [1].\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "Lyft's revenue in 2024 was $5,786,016,000 [1]."
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "display(Markdown(await agentic_rag(\"List me down new LLMs in 2025\")))"
      ],
      "metadata": {
        "id": "Mdb97ckP6y2h",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "dd2f0f27-1d2c-4a82-a9d4-3052f73fa175"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m\u001b[96m👤 User Query:\u001b[0m List me down new LLMs in 2025\n",
            "\n",
            "\u001b[90m📍 Selected Route: INTERNET_QUERY\n",
            "📝 Reason: The query is about new LLMs in 2025, which requires current information beyond the training data.\n",
            "⚙️ Processing query...\u001b[0m\n",
            "\n",
            "Getting your response from the internet 🌐 ...\n",
            "\u001b[1m\u001b[96m🤖 BOT RESPONSE:\u001b[0m\n",
            "\n",
            "### New LLMs Released in 2025\n",
            "\n",
            "1. **Gemini 2.0 Flash** - Released by Google DeepMind on December 11, 2024.\n",
            "2. **Sora** - Developed by OpenAI, released on December 9, 2024.\n",
            "3. **Nova** - Created by Amazon, released on December 3, 2024.\n",
            "4. **Claude 3.5 Sonnet** - Released by Anthropic, date not specified but noted as a significant model.\n",
            "5. **LLaMA 3** - A new version from Meta.\n",
            "6. **Google Gemma 2** - An updated model from Google.\n",
            "7. **Command R+** - A new model focusing on enhanced performance.\n",
            "8. **Mistral-8x22b** - A model known for its efficiency.\n",
            "9. **Falcon 2** - An updated version of the Falcon series.\n",
            "10. **Grok 1.5** - A new iteration of the Grok model.\n",
            "11. **Qwen 1.5** - An updated version of the Qwen model.\n",
            "12. **BLOOM** - Continues to be relevant in the LLM landscape.\n",
            "\n",
            "These models represent some of the latest advancements in large language models as of May 2025. For more detailed comparisons and insights, you can refer to the following sources:\n",
            "\n",
            "- [Zapier - The best large language models (LLMs) in 2025](https://zapier.com/blog/best-llm/)\n",
            "- [Exploding Topics - Best 44 Large Language Models (LLMs) in 2025](https://explodingtopics.com/blog/list-of-llms)\n",
            "- [NetApp Instaclustr - Top 10 open source LLMs for 2025](https://www.instaclustr.com/education/top-10-open-source-llms-for-2025/)\n",
            "- [TechTarget - 25 of the best large language models in 2025](https://www.techtarget.com/whatis/feature/12-of-the-best-large-language-models)\n",
            "- [Empler - The Ultimate Guide to the Latest LLMs](https://www.empler.ai/blog/the-ultimate-guide-to-the-latest-llms-a-detailed-comparison-for-2025)\n",
            "- [Hatchworks - Large Language Models: What You Need to Know in 2025](https://hatchworks.com/blog/gen-ai/large-language-models-guide/)\n",
            "- [HeLa Labs - 7 Best Large Language Models to Check in 2025](https://helalabs.com/blog/7-best-large-language-models-to-check-in-2025/)\n",
            "- [Simon W - What's new in the world of LLMs, for NICAR 2025](https://simonw.substack.com/p/whats-new-in-the-world-of-llms-for)\n",
            "- [Prajna AI Wisdom - LLM Trends 2025](https://prajnaaiwisdom.medium.com/llm-trends-2025-a-deep-dive-into-the-future-of-large-language-models-bff23aa7cdbc)\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "### New LLMs Released in 2025\n\n1. **Gemini 2.0 Flash** - Released by Google DeepMind on December 11, 2024.\n2. **Sora** - Developed by OpenAI, released on December 9, 2024.\n3. **Nova** - Created by Amazon, released on December 3, 2024.\n4. **Claude 3.5 Sonnet** - Released by Anthropic, date not specified but noted as a significant model.\n5. **LLaMA 3** - A new version from Meta.\n6. **Google Gemma 2** - An updated model from Google.\n7. **Command R+** - A new model focusing on enhanced performance.\n8. **Mistral-8x22b** - A model known for its efficiency.\n9. **Falcon 2** - An updated version of the Falcon series.\n10. **Grok 1.5** - A new iteration of the Grok model.\n11. **Qwen 1.5** - An updated version of the Qwen model.\n12. **BLOOM** - Continues to be relevant in the LLM landscape.\n\nThese models represent some of the latest advancements in large language models as of May 2025. For more detailed comparisons and insights, you can refer to the following sources:\n\n- [Zapier - The best large language models (LLMs) in 2025](https://zapier.com/blog/best-llm/)\n- [Exploding Topics - Best 44 Large Language Models (LLMs) in 2025](https://explodingtopics.com/blog/list-of-llms)\n- [NetApp Instaclustr - Top 10 open source LLMs for 2025](https://www.instaclustr.com/education/top-10-open-source-llms-for-2025/)\n- [TechTarget - 25 of the best large language models in 2025](https://www.techtarget.com/whatis/feature/12-of-the-best-large-language-models)\n- [Empler - The Ultimate Guide to the Latest LLMs](https://www.empler.ai/blog/the-ultimate-guide-to-the-latest-llms-a-detailed-comparison-for-2025)\n- [Hatchworks - Large Language Models: What You Need to Know in 2025](https://hatchworks.com/blog/gen-ai/large-language-models-guide/)\n- [HeLa Labs - 7 Best Large Language Models to Check in 2025](https://helalabs.com/blog/7-best-large-language-models-to-check-in-2025/)\n- [Simon W - What's new in the world of LLMs, for NICAR 2025](https://simonw.substack.com/p/whats-new-in-the-world-of-llms-for)\n- [Prajna AI Wisdom - LLM Trends 2025](https://prajnaaiwisdom.medium.com/llm-trends-2025-a-deep-dive-into-the-future-of-large-language-models-bff23aa7cdbc)"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "display(Markdown(await agentic_rag(\"how to work with chat completions?\")))"
      ],
      "metadata": {
        "id": "wpO6W8peh1qO",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 527
        },
        "outputId": "f7352ab1-ef87-48fb-8056-f059298d2185"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m\u001b[96m👤 User Query:\u001b[0m how to work with chat completions?\n",
            "\n",
            "\u001b[90m📍 Selected Route: OPENAI_QUERY\n",
            "📝 Reason: Working with chat completions is related to OpenAI's API and services.\n",
            "⚙️ Processing query...\u001b[0m\n",
            "\n",
            "\u001b[1m\u001b[96m🤖 BOT RESPONSE:\u001b[0m\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "To work with chat completions, you will be primarily dealing with retrieving stored chat completions, and getting chat messages. Here is an overview of how it works:\n\n1. Get Stored Chat Completions:\nYou can get a list of stored chat completions using the OpenAI API. In terms of parameters required, you can specify the identifier for the last chat completion from the previous pagination request using 'after' string which is optional, set the number of Chat completions to retrieve with the 'limit' integer, also optional and defaults to 20, and you can use the 'model' string to specify the model used to generate the Chat Completions, this is also optional[^1^]\n\n2. Get Chat Messages:\nYou can get the messages in a stored chat completion using the OpenAI API as well. This refers to only those chat completions that have been created with the 'store' parameter set to true. Path parameters are used to specify the ID of the chat completion to retrieve [^1^]. You can also sort the order in which these messages are retrieved by timestamp using the 'order' string which defaults to ascending (asc) order[^1^].\n\n3. Get Chat Completion:\nIn order to get a specific chat completion, you again use the OpenAI API specifying the ID of the chat completion in the 'completion_id' string required parameter[^1^].\n\nExample of API call:\n\n     curl https://api.openai.com/v1/chat/completions/chatcmpl-abc123 \\\\\n      -H \"Authorization: Bearer $OPENAI_API_KEY\" \\\\\n      -H \"Content-Type: application/json\" [^1^]\n\nAn example response structure :\n\n       {\n  \"object\": \"chat.completion\",\n  \"id\": \"chatcmpl-abc123\",\n  \"model\": \"gpt-4o-2024-08-06\",\n  ....\n} [^1^]\n[^1^]: https://platform.openai.com/docs/api-reference/introduction"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Assignment: Implement sub-query division"
      ],
      "metadata": {
        "id": "DKagaRyI4jaK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In our current agentic retrieval-augmented generation (RAG) setup, there's a key limitation: when a user submits a query that contains multiple distinct questions phrased as a single input, the system treats it as a single unified search. As a result, the retrieval engine performs only one operation on the vector databases or external tools, which often leads to incomplete or less relevant results.\n",
        "\n",
        "\n",
        "To address this, the assignment introduces a new functionality called subquery division. This involves breaking down complex, compound queries into multiple, focused subqueries. Each subquery is processed independently, allowing the system to retrieve more accurate and context-specific information. By handling these subqueries separately, the agent can generate more complete and relevant responses."
      ],
      "metadata": {
        "id": "JZvmbi0QxPzD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pydantic import BaseModel, Field\n",
        "from typing import List\n",
        "\n",
        "class SubQueriesList(BaseModel):\n",
        "    subQueries: List[str] = Field(...,\n",
        "                             description=\"\"\"A list of distinct sub-questions derived from the user query.\n",
        "                              If the query is singular, this list will contain one item.\"\"\")"
      ],
      "metadata": {
        "id": "7LN2gpeO1pZg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "async def sub_queries(user_query):\n",
        "  sub_queries_prompt= f\"\"\"\n",
        "  You are a query router. If the input contains multiple distinct questions, break it into sub-questions.\"\"\"\n",
        "\n",
        "  response = await litellm.acompletion(\n",
        "        model=\"gpt-4o\",\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": sub_queries_prompt},\n",
        "            {\"role\": \"user\", \"content\": user_query},\n",
        "\n",
        "        ],\n",
        "        response_format=SubQueriesList,\n",
        "        temperature=0.0,\n",
        "    )\n",
        "  json_response = response.choices[0].message.content\n",
        "  output = SubQueriesList.model_validate_json(json_response)\n",
        "  return output.subQueries\n"
      ],
      "metadata": {
        "id": "DBq_Y-w1B0DF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "composite_query = \"what is revenue of lyft and what is reveue for uber in 2024\"\n",
        "sub_query_list = await sub_queries(composite_query)\n",
        "print(sub_query_list)"
      ],
      "metadata": {
        "id": "ldR3RgLLw3UE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "90870c10-5f7b-44ef-d5c9-c0c5083966a3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['What is the revenue of Lyft in 2024?', 'What is the revenue of Uber in 2024?']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "async def process_queries_with_agentic_rag(user_query: str):\n",
        "    \"\"\"\n",
        "    Processes composite queries by splitting them into sub‑queries,\n",
        "    handling each sub‑query with the agentic_rag system, and then\n",
        "    merging the individual answers into one cohesive response.\n",
        "\n",
        "    Args:\n",
        "        user_query (str): The user's original composite query.\n",
        "\n",
        "    Returns:\n",
        "        str: A synthesized answer to the original query.\n",
        "    \"\"\"\n",
        "\n",
        "    #  Terminal colour codes\n",
        "    BLUE    = \"\\033[94m\"   # user input / initial query\n",
        "    MAGENTA = \"\\033[95m\"   # headings & final response\n",
        "    GREEN   = \"\\033[92m\"   # processing / success\n",
        "    GREY    = \"\\033[90m\"   # info & sub‑query lists\n",
        "    RED     = \"\\033[91m\"   # errors\n",
        "    DIM     = \"\\033[2m\"    # dimmed text\n",
        "    BOLD    = \"\\033[1m\"    # emphasis\n",
        "    RESET   = \"\\033[0m\"    # reset to default\n",
        "\n",
        "    try:\n",
        "        # 1️. Show the original query\n",
        "        print(f\"{BOLD}{BLUE}📝  Composite Query:{RESET} {user_query}\\n\")\n",
        "\n",
        "        # 2️. Break the query into sub‑queries\n",
        "        sub_query_list = await sub_queries(user_query)\n",
        "        print(f\"{DIM}{GREY}🔎  Breaking into sub‑queries…{RESET}\")\n",
        "        for idx, sub_q in enumerate(sub_query_list, start=1):\n",
        "            print(f\"{DIM}{GREY}   {idx}. {sub_q}{RESET}\")\n",
        "\n",
        "        # 3️. Process the sub‑queries concurrently\n",
        "        print(f\"{DIM}{GREEN}⚡  Processing sub‑queries in parallel using async …{RESET}\\n\")\n",
        "        tasks = [agentic_rag(q) for q in sub_query_list]\n",
        "        individual_results = await asyncio.gather(*tasks)\n",
        "\n",
        "        # 4️. If only one sub‑query, return its answer straight away\n",
        "        if len(sub_query_list) == 1:\n",
        "            print(f\"{BOLD}{MAGENTA}🤖  Final Response:{RESET}\\n\")\n",
        "            print(individual_results[0])\n",
        "            return individual_results[0]\n",
        "\n",
        "        # 5️. Combine multiple answers into a single response\n",
        "        print(f\"{DIM}{GREY}🧩  Synthesising answers…{RESET}\\n\")\n",
        "        mapping = \"\\n\\n\".join(\n",
        "            f\"Sub‑query: {q}\\nAnswer: {a}\" for q, a in zip(sub_query_list, individual_results)\n",
        "        )\n",
        "\n",
        "        combine_prompt = f\"\"\"\n",
        "\n",
        "        Original user query: {user_query}\n",
        "        The query was divided and answered as follows:\n",
        "\n",
        "        {mapping}\n",
        "\n",
        "        Please merge these answers into a single, well‑structured reply that\n",
        "        addresses the original question directly.\n",
        "            - Use clear Markdown in your response\n",
        "\n",
        "        \"\"\"\n",
        "\n",
        "        response = await litellm.acompletion(\n",
        "            model=\"gpt-4o\",\n",
        "            messages=[\n",
        "                {\n",
        "                    \"role\": \"system\",\n",
        "                    \"content\": \"You are a helpful assistant that synthesizes multiple pieces of information into cohesive answers.\"\n",
        "                },\n",
        "                {\"role\": \"user\", \"content\": combine_prompt},\n",
        "            ],\n",
        "            temperature=0.1,\n",
        "        )\n",
        "\n",
        "        final_result = response.choices[0].message.content\n",
        "\n",
        "        # 6️.  Print and return the merged answer\n",
        "        print(f\"{BOLD}{MAGENTA}🤖  Final Synthesised Response:{RESET}\\n\")\n",
        "        return final_result\n",
        "\n",
        "    except Exception as err:\n",
        "        # 7️. Catch‑all for unexpected errors\n",
        "        error_msg = f\"Unexpected error in composite query processing: {err}\"\n",
        "        print(f\"{BOLD}{RED}💥  Error:{RESET}\\n{error_msg}\\n\")\n",
        "        return error_msg"
      ],
      "metadata": {
        "id": "Y18pz0-pVCKS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "display(Markdown(await process_queries_with_agentic_rag(composite_query)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 585
        },
        "id": "PUq7vbWf4XJ4",
        "outputId": "0cff2f72-e8ec-4ea3-a760-f1b18ffa5f9c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m\u001b[94m📝  Composite Query:\u001b[0m what is revenue of lyft and what is reveue for uber in 2024\n",
            "\n",
            "\u001b[2m\u001b[90m🔎  Breaking into sub‑queries…\u001b[0m\n",
            "\u001b[2m\u001b[90m   1. What is the revenue of Lyft in 2024?\u001b[0m\n",
            "\u001b[2m\u001b[90m   2. What is the revenue of Uber in 2024?\u001b[0m\n",
            "\u001b[2m\u001b[92m⚡  Processing sub‑queries in parallel…\u001b[0m\n",
            "\n",
            "\u001b[1m\u001b[96m👤 User Query:\u001b[0m What is the revenue of Lyft in 2024?\n",
            "\n",
            "\u001b[1m\u001b[96m👤 User Query:\u001b[0m What is the revenue of Uber in 2024?\n",
            "\n",
            "\u001b[90m📍 Selected Route: 10K_DOCUMENT_QUERY\n",
            "📝 Reason: Query related to annual financial data of a company\n",
            "⚙️ Processing query...\u001b[0m\n",
            "\n",
            "\u001b[90m📍 Selected Route: 10K_DOCUMENT_QUERY\n",
            "📝 Reason: The query is asking for specific financial data from a company's annual report, which is typically found in 10-K filings.\n",
            "⚙️ Processing query...\u001b[0m\n",
            "\n",
            "\u001b[1m\u001b[96m🤖 BOT RESPONSE:\u001b[0m\n",
            "\n",
            "The revenue of Uber in 2024 was $5,786,016,000[1].\n",
            "\n",
            "\u001b[1m\u001b[96m🤖 BOT RESPONSE:\u001b[0m\n",
            "\n",
            "The revenue of Lyft in 2024 was $5,786,016,000 [2].\n",
            "\n",
            "\u001b[2m\u001b[90m🧩  Synthesising answers…\u001b[0m\n",
            "\n",
            "\u001b[1m\u001b[95m🤖  Final Synthesised Response:\u001b[0m\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "In 2024, the revenue for both Lyft and Uber was reported to be $5,786,016,000."
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "new_query = 'Where is Taj Mahal and who won NFL in 2024'\n",
        "display(Markdown(await process_queries_with_agentic_rag(new_query)))"
      ],
      "metadata": {
        "id": "UkqIyE6z4Zcn",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 784
        },
        "outputId": "05b5f456-9a97-41c5-d4ee-207a6b7c5d8e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m\u001b[94m📝  Composite Query:\u001b[0m Where is Taj Mahal and who won NFL in 2024\n",
            "\n",
            "\u001b[2m\u001b[90m🔎  Breaking into sub‑queries…\u001b[0m\n",
            "\u001b[2m\u001b[90m   1. Where is the Taj Mahal located?\u001b[0m\n",
            "\u001b[2m\u001b[90m   2. Who won the NFL in 2024?\u001b[0m\n",
            "\u001b[2m\u001b[92m⚡  Processing sub‑queries in parallel…\u001b[0m\n",
            "\n",
            "\u001b[1m\u001b[96m👤 User Query:\u001b[0m Where is the Taj Mahal located?\n",
            "\n",
            "\u001b[1m\u001b[96m👤 User Query:\u001b[0m Who won the NFL in 2024?\n",
            "\n",
            "\u001b[90m📍 Selected Route: INTERNET_QUERY\n",
            "📝 Reason: The query is about a recent event outcome, which requires current information not covered by OpenAI or 10-K documents.\n",
            "⚙️ Processing query...\u001b[0m\n",
            "\n",
            "Getting your response from the internet 🌐 ...\n",
            "\u001b[90m📍 Selected Route: INTERNET_QUERY\n",
            "📝 Reason: The query is about a geographical location, not related to OpenAI or 10-K documents.\n",
            "⚙️ Processing query...\u001b[0m\n",
            "\n",
            "Getting your response from the internet 🌐 ...\n",
            "\u001b[1m\u001b[96m🤖 BOT RESPONSE:\u001b[0m\n",
            "\n",
            "The Taj Mahal is located in Agra, Uttar Pradesh, India. It is situated on the right bank of the Yamuna River within a vast Mughal garden that spans nearly 17 hectares. The exact address is:\n",
            "\n",
            "**Taj Mahal, Agra, Uttar Pradesh, India**. \n",
            "\n",
            "The mausoleum was commissioned in 1631 by Mughal Emperor Shah Jahan in memory of his wife, Mumtaz Mahal.\n",
            "\n",
            "\u001b[1m\u001b[96m🤖 BOT RESPONSE:\u001b[0m\n",
            "\n",
            "The Kansas City Chiefs won the NFL in 2024, specifically Super Bowl LVIII. They defeated the San Francisco 49ers with a score of 25-22 in an overtime thriller. The game took place on February 11, 2024, at Allegiant Stadium in Las Vegas. This victory marked the Chiefs' second consecutive Super Bowl win, making them the first NFL team since the 2004 New England Patriots to achieve back-to-back championships. Patrick Mahomes was named the MVP of the game.\n",
            "\n",
            "\u001b[2m\u001b[90m🧩  Synthesising answers…\u001b[0m\n",
            "\n",
            "\u001b[1m\u001b[95m🤖  Final Synthesised Response:\u001b[0m\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "The Taj Mahal is located in Agra, Uttar Pradesh, India. It is situated on the right bank of the Yamuna River within a vast Mughal garden that spans nearly 17 hectares. The mausoleum was commissioned in 1631 by Mughal Emperor Shah Jahan in memory of his wife, Mumtaz Mahal.\n\nAs for the NFL in 2024, the Kansas City Chiefs won Super Bowl LVIII. They defeated the San Francisco 49ers with a score of 25-22 in an overtime thriller. The game took place on February 11, 2024, at Allegiant Stadium in Las Vegas. This victory marked the Chiefs' second consecutive Super Bowl win, making them the first NFL team since the 2004 New England Patriots to achieve back-to-back championships. Patrick Mahomes was named the MVP of the game."
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "new_query = 'What is Hakuna Matata'\n",
        "display(Markdown(await process_queries_with_agentic_rag(new_query)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "NCyEvPjk8_4O",
        "outputId": "997e955b-df8b-4cf5-a613-d98592af7b48"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m\u001b[94m📝  Composite Query:\u001b[0m What is Hakuna Matata\n",
            "\n",
            "\u001b[2m\u001b[90m🔎  Breaking into sub‑queries…\u001b[0m\n",
            "\u001b[2m\u001b[90m   1. What is the meaning of 'Hakuna Matata'?\u001b[0m\n",
            "\u001b[2m\u001b[90m   2. Where does the phrase 'Hakuna Matata' originate from?\u001b[0m\n",
            "\u001b[2m\u001b[90m   3. How is 'Hakuna Matata' used in popular culture?\u001b[0m\n",
            "\u001b[2m\u001b[92m⚡  Processing sub‑queries in parallel…\u001b[0m\n",
            "\n",
            "\u001b[1m\u001b[96m👤 User Query:\u001b[0m What is the meaning of 'Hakuna Matata'?\n",
            "\n",
            "\u001b[1m\u001b[96m👤 User Query:\u001b[0m Where does the phrase 'Hakuna Matata' originate from?\n",
            "\n",
            "\u001b[1m\u001b[96m👤 User Query:\u001b[0m How is 'Hakuna Matata' used in popular culture?\n",
            "\n",
            "\u001b[90m📍 Selected Route: INTERNET_QUERY\n",
            "📝 Reason: The query is about cultural references and usage, which requires a broader search beyond specific databases or documentation.\n",
            "⚙️ Processing query...\u001b[0m\n",
            "\n",
            "Getting your response from the internet 🌐 ...\n",
            "\u001b[90m📍 Selected Route: INTERNET_QUERY\n",
            "📝 Reason: The query is about the origin of a phrase, which is not related to OpenAI or 10-K documents.\n",
            "⚙️ Processing query...\u001b[0m\n",
            "\n",
            "Getting your response from the internet 🌐 ...\n",
            "\u001b[90m📍 Selected Route: INTERNET_QUERY\n",
            "📝 Reason: The phrase 'Hakuna Matata' is a cultural reference and not specific to OpenAI or 10-K documents.\n",
            "⚙️ Processing query...\u001b[0m\n",
            "\n",
            "Getting your response from the internet 🌐 ...\n",
            "\u001b[1m\u001b[96m🤖 BOT RESPONSE:\u001b[0m\n",
            "\n",
            "The phrase \"Hakuna Matata\" originates from the Swahili language, which is spoken in East Africa. It translates to \"no worries\" or \"no problems.\" The term is composed of two parts: \"hakuna,\" meaning \"there is/are not\" or \"no,\" and \"matata,\" which is the plural form of \"trouble\" or \"problems.\" \n",
            "\n",
            "The phrase gained widespread popularity through its use in the 1994 Disney animated film \"The Lion King,\" where it is featured in a song performed by the characters Timon and Pumbaa. The phrase has since become a cultural catchphrase, often associated with a carefree attitude. \n",
            "\n",
            "For more information, you can refer to the following sources:\n",
            "- [Wikipedia - Hakuna Matata](https://en.wikipedia.org/wiki/Hakuna_matata)\n",
            "- [Dictionary.com - Hakuna Matata Meaning & Origin](https://www.dictionary.com/e/slang/hakuna-matata/)\n",
            "- [Altezza Travel - Hakuna Matata meaning](https://altezzatravel.com/articles/hakuna-matata-meaning)\n",
            "\n",
            "\u001b[1m\u001b[96m🤖 BOT RESPONSE:\u001b[0m\n",
            "\n",
            "\"Hakuna Matata\" is a Swahili phrase that translates to \"no trouble\" or \"no worries\" in English. It conveys a sense of living without stress and taking it easy. The phrase gained widespread popularity through the 1994 Disney movie \"The Lion King,\" where it is featured prominently in a song that emphasizes a carefree philosophy. \n",
            "\n",
            "For more information, you can visit the following links:\n",
            "- [Wikipedia - Hakuna Matata](https://en.wikipedia.org/wiki/Hakuna_matata)\n",
            "- [Dictionary.com - Hakuna Matata Meaning & Origin](https://www.dictionary.com/e/slang/hakuna-matata/)\n",
            "- [Classic FM - What does 'Hakuna matata' in The Lion King actually mean?](https://www.classicfm.com/discover-music/hakuna-matata-lyrics-meaning-lion-king/)\n",
            "\n",
            "\u001b[1m\u001b[96m🤖 BOT RESPONSE:\u001b[0m\n",
            "\n",
            "1. **Usage in Disney's The Lion King**: \"Hakuna Matata\" is a Swahili phrase meaning \"no worries\" or \"no trouble.\" It gained immense popularity through the 1994 Disney animated film \"The Lion King,\" where it is featured in a song performed by the characters Timon and Pumbaa. The song encapsulates a carefree philosophy, encouraging a relaxed approach to life.\n",
            "\n",
            "2. **Cultural Impact**: The phrase has transcended its original context and is widely recognized globally. It has become synonymous with a laid-back attitude and is often used in various contexts to promote a stress-free lifestyle.\n",
            "\n",
            "3. **Pop Culture Programming**: The phrase has been utilized in various pop culture programming, particularly aimed at younger audiences. For example, a program for tweens (ages 9-12) was themed around \"Hakuna Matata,\" highlighting its relevance in contemporary youth culture.\n",
            "\n",
            "4. **Ironic Interpretations**: Discussions around the phrase often include ironic interpretations, such as the idea that while \"Hakuna Matata\" promotes a carefree attitude, it can lead to neglecting responsibilities, as illustrated in the narrative of \"The Lion King\" where Simba avoids his duties for years.\n",
            "\n",
            "5. **Trademark Controversy**: Disney's attempt to trademark \"Hakuna Matata\" sparked discussions and reactions from Swahili speakers, who felt that the phrase, which is part of their cultural heritage, should not be owned by a corporation.\n",
            "\n",
            "6. **Other Media**: The phrase has appeared in various forms of media beyond \"The Lion King,\" including music, social media, and discussions about its philosophical implications, often critiquing its idealism and practicality in real life.\n",
            "\n",
            "7. **Online Presence**: The phrase continues to be popular on platforms like YouTube, where performances of the song from \"The Lion King\" can be found, showcasing its lasting appeal in music and entertainment. \n",
            "\n",
            "For more information, you can explore the following links:\n",
            "- [Hakuna Matata - Wikipedia](https://en.wikipedia.org/wiki/Hakuna_matata)\n",
            "- [Pop Culture Programming: Hakuna Matata - ALSC Blog](https://www.alsc.ala.org/blog/2019/07/pop-culture-programming-hakuna-matata/)\n",
            "- [Swahili Speakers React To Disney's Trademark of 'Hakuna Matata'](https://www.npr.org/sections/goatsandsoda/2018/12/14/676703629/swahili-speakers-horrified-by-disneys-trademark-of-hakuna-matata)\n",
            "\n",
            "\u001b[2m\u001b[90m🧩  Synthesising answers…\u001b[0m\n",
            "\n",
            "\u001b[1m\u001b[95m🤖  Final Synthesised Response:\u001b[0m\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "**Hakuna Matata: Meaning, Origin, and Cultural Impact**\n\n**Meaning and Origin**\n\n\"Hakuna Matata\" is a Swahili phrase that translates to \"no worries\" or \"no trouble\" in English. It is composed of two parts: \"hakuna,\" meaning \"there is/are not\" or \"no,\" and \"matata,\" which is the plural form of \"trouble\" or \"problems.\" This phrase originates from the Swahili language, spoken widely in East Africa.\n\n**Cultural Impact and Popular Usage**\n\nThe phrase gained international fame through its prominent use in Disney's 1994 animated film *The Lion King*. In the movie, \"Hakuna Matata\" is featured in a song performed by the characters Timon and Pumbaa, encapsulating a carefree philosophy that encourages living without stress and taking life easy.\n\nBeyond *The Lion King*, \"Hakuna Matata\" has become a global cultural catchphrase, symbolizing a laid-back attitude. It is often used in various contexts to promote a stress-free lifestyle. However, discussions around the phrase sometimes include ironic interpretations, suggesting that while it promotes a carefree attitude, it can lead to neglecting responsibilities, as illustrated by Simba's avoidance of his duties in the film.\n\n**Trademark Controversy**\n\nDisney's attempt to trademark \"Hakuna Matata\" sparked controversy, particularly among Swahili speakers who felt that the phrase, part of their cultural heritage, should not be owned by a corporation. This controversy highlighted the broader issues of cultural appropriation and the commercialization of traditional expressions.\n\n**Presence in Pop Culture**\n\nThe phrase continues to be popular in various forms of media, including music, social media, and discussions about its philosophical implications. It has appeared in pop culture programming aimed at younger audiences and is frequently referenced in discussions about its idealism and practicality in real life.\n\n**Online and Media Presence**\n\n\"Hakuna Matata\" maintains a strong online presence, with performances of the song from *The Lion King* available on platforms like YouTube, showcasing its lasting appeal in music and entertainment.\n\nFor more detailed information, you can explore the following resources:\n- [Wikipedia - Hakuna Matata](https://en.wikipedia.org/wiki/Hakuna_matata)\n- [Dictionary.com - Hakuna Matata Meaning & Origin](https://www.dictionary.com/e/slang/hakuna-matata/)\n- [Swahili Speakers React To Disney's Trademark of 'Hakuna Matata'](https://www.npr.org/sections/goatsandsoda/2018/12/14/676703629/swahili-speakers-horrified-by-disneys-trademark-of-hakuna-matata)"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "new_query = 'Who is Max Verstappen\\'s dad? '\n",
        "display(Markdown(await process_queries_with_agentic_rag(new_query)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 643
        },
        "id": "X2FwCYY29tuD",
        "outputId": "49884873-cbba-48bd-a489-02bd8dee6ef0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m\u001b[94m📝  Composite Query:\u001b[0m Who is Max Verstappen's dad? \n",
            "\n",
            "\u001b[2m\u001b[90m🔎  Breaking into sub‑queries…\u001b[0m\n",
            "\u001b[2m\u001b[90m   1. Who is Max Verstappen's dad?\u001b[0m\n",
            "\u001b[2m\u001b[92m⚡  Processing sub‑queries in parallel…\u001b[0m\n",
            "\n",
            "\u001b[1m\u001b[96m👤 User Query:\u001b[0m Who is Max Verstappen's dad?\n",
            "\n",
            "\u001b[90m📍 Selected Route: INTERNET_QUERY\n",
            "📝 Reason: The query is about a public figure's family, which is not related to OpenAI or 10-K documents.\n",
            "⚙️ Processing query...\u001b[0m\n",
            "\n",
            "Getting your response from the internet 🌐 ...\n",
            "\u001b[1m\u001b[96m🤖 BOT RESPONSE:\u001b[0m\n",
            "\n",
            "Max Verstappen's dad is Jos Verstappen. \n",
            "\n",
            "- Jos Verstappen is a former Formula 1 driver who competed in F1 from 1994 to 2003.\n",
            "- He participated in 106 races and achieved two podium finishes during his career, driving for teams such as Benetton, Arrows, and Minardi.\n",
            "- Jos has been a significant influence on Max's racing career, often described as a strict and uncompromising mentor who pushed Max to excel in motorsport.\n",
            "- He has been involved in Max's development as a driver from a young age, shaping his skills and approach to racing.\n",
            "\n",
            "\u001b[1m\u001b[95m🤖  Final Response:\u001b[0m\n",
            "\n",
            "Max Verstappen's dad is Jos Verstappen. \n",
            "\n",
            "- Jos Verstappen is a former Formula 1 driver who competed in F1 from 1994 to 2003.\n",
            "- He participated in 106 races and achieved two podium finishes during his career, driving for teams such as Benetton, Arrows, and Minardi.\n",
            "- Jos has been a significant influence on Max's racing career, often described as a strict and uncompromising mentor who pushed Max to excel in motorsport.\n",
            "- He has been involved in Max's development as a driver from a young age, shaping his skills and approach to racing.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "Max Verstappen's dad is Jos Verstappen. \n\n- Jos Verstappen is a former Formula 1 driver who competed in F1 from 1994 to 2003.\n- He participated in 106 races and achieved two podium finishes during his career, driving for teams such as Benetton, Arrows, and Minardi.\n- Jos has been a significant influence on Max's racing career, often described as a strict and uncompromising mentor who pushed Max to excel in motorsport.\n- He has been involved in Max's development as a driver from a young age, shaping his skills and approach to racing."
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2VFwYnvU-JRN"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "1bab9a14081841bdb36625f4a98a36d7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ee98662d3e954463908bebf5e9a3f9dd",
              "IPY_MODEL_a2fab8920327413e8f1a9d4e636003c7",
              "IPY_MODEL_bf72c3e67d21431b8425d0e1fbd52ffb"
            ],
            "layout": "IPY_MODEL_cdff734ffbbe40a3b12126a8bdd834e0"
          }
        },
        "ee98662d3e954463908bebf5e9a3f9dd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7ef64ffcbcd34270b7862fdcc68b99ae",
            "placeholder": "​",
            "style": "IPY_MODEL_25e8ec5de5db40a09816f1d69bd7fba6",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "a2fab8920327413e8f1a9d4e636003c7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9b8e16ccb6c64a799866181ee14dcafc",
            "max": 1191,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0e802fdaddd944929558e6796a1de701",
            "value": 1191
          }
        },
        "bf72c3e67d21431b8425d0e1fbd52ffb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b6f993dce2414cacbb3c471bb6a3f14c",
            "placeholder": "​",
            "style": "IPY_MODEL_f7f0bb0337d043b992ab77df8e8f1345",
            "value": " 1.19k/1.19k [00:00&lt;00:00, 53.3kB/s]"
          }
        },
        "cdff734ffbbe40a3b12126a8bdd834e0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7ef64ffcbcd34270b7862fdcc68b99ae": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "25e8ec5de5db40a09816f1d69bd7fba6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9b8e16ccb6c64a799866181ee14dcafc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0e802fdaddd944929558e6796a1de701": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b6f993dce2414cacbb3c471bb6a3f14c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f7f0bb0337d043b992ab77df8e8f1345": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "852de2b2421f417abc20dc2d483c8d0c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9d0a93c2c7d147a19dc39a1128161277",
              "IPY_MODEL_7963cc544dec4beb981907da069ca2bc",
              "IPY_MODEL_adc78f8e66a14b76b38b9be63fa83a33"
            ],
            "layout": "IPY_MODEL_d8d002f7161944bbb79014ea1cac9acd"
          }
        },
        "9d0a93c2c7d147a19dc39a1128161277": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_59ea57f4c24f43769fd10135b409a9aa",
            "placeholder": "​",
            "style": "IPY_MODEL_8bff07949b004dfda01aa6255a0deefa",
            "value": "vocab.txt: 100%"
          }
        },
        "7963cc544dec4beb981907da069ca2bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5c01d1aec339408297a633c34990603d",
            "max": 231508,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e3302658450047c592b04e4859d3d5e9",
            "value": 231508
          }
        },
        "adc78f8e66a14b76b38b9be63fa83a33": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3970aa19967d4e0a88afd91b8da5153b",
            "placeholder": "​",
            "style": "IPY_MODEL_271308838afd45bc8b5e91ca2e86c106",
            "value": " 232k/232k [00:00&lt;00:00, 3.63MB/s]"
          }
        },
        "d8d002f7161944bbb79014ea1cac9acd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "59ea57f4c24f43769fd10135b409a9aa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8bff07949b004dfda01aa6255a0deefa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5c01d1aec339408297a633c34990603d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e3302658450047c592b04e4859d3d5e9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3970aa19967d4e0a88afd91b8da5153b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "271308838afd45bc8b5e91ca2e86c106": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8fb0ad2ea6f042fda8db65992087f995": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_24c7e03b975f4e2ca81662d1908a70de",
              "IPY_MODEL_1953ea27661d4f8d9eaee29bbd8fa6a2",
              "IPY_MODEL_fc364d1578b34fbdb847fd40cb41a67b"
            ],
            "layout": "IPY_MODEL_01d488d6abb346b8994b54b9e18f6a1a"
          }
        },
        "24c7e03b975f4e2ca81662d1908a70de": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ce30a52b628a452f994f481115385c9c",
            "placeholder": "​",
            "style": "IPY_MODEL_4a1677480b90499c89276cad462b023c",
            "value": "tokenizer.json: 100%"
          }
        },
        "1953ea27661d4f8d9eaee29bbd8fa6a2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_af684197bd7c45369fca9c5f1a9377b6",
            "max": 711396,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1c4403779e21403f99d72d6b7a91ed53",
            "value": 711396
          }
        },
        "fc364d1578b34fbdb847fd40cb41a67b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b7694849e5c1497f99a700229c688749",
            "placeholder": "​",
            "style": "IPY_MODEL_0817f56372244726bfde7cae38194c73",
            "value": " 711k/711k [00:00&lt;00:00, 9.06MB/s]"
          }
        },
        "01d488d6abb346b8994b54b9e18f6a1a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ce30a52b628a452f994f481115385c9c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4a1677480b90499c89276cad462b023c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "af684197bd7c45369fca9c5f1a9377b6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1c4403779e21403f99d72d6b7a91ed53": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b7694849e5c1497f99a700229c688749": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0817f56372244726bfde7cae38194c73": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3414c4b6ecf048f1a8030e1ea8e075d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ff6c63fd177745148944fe8479857972",
              "IPY_MODEL_744fefcc324346cea04095ef9122aa46",
              "IPY_MODEL_e255db904b4247b79e3fec6bf550a4b2"
            ],
            "layout": "IPY_MODEL_97b45b217dd74ac1989f7db8914fbcf6"
          }
        },
        "ff6c63fd177745148944fe8479857972": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_527aab6bd18d444ba442a00bcd8090cc",
            "placeholder": "​",
            "style": "IPY_MODEL_91d3978d47dc427ca431050da101f6a1",
            "value": "special_tokens_map.json: 100%"
          }
        },
        "744fefcc324346cea04095ef9122aa46": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cb29e12b30dc43f8aaa3f707236ba7e8",
            "max": 695,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_58af76d7d4a24ff7bdf07f50d3bd42ca",
            "value": 695
          }
        },
        "e255db904b4247b79e3fec6bf550a4b2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3ccc2952581349cd8f066f6187b4effe",
            "placeholder": "​",
            "style": "IPY_MODEL_86558585c8c242daad91f2729100f1d6",
            "value": " 695/695 [00:00&lt;00:00, 70.7kB/s]"
          }
        },
        "97b45b217dd74ac1989f7db8914fbcf6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "527aab6bd18d444ba442a00bcd8090cc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "91d3978d47dc427ca431050da101f6a1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cb29e12b30dc43f8aaa3f707236ba7e8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "58af76d7d4a24ff7bdf07f50d3bd42ca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3ccc2952581349cd8f066f6187b4effe": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "86558585c8c242daad91f2729100f1d6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "34a67b3b09fd4f24bfc2cf635c5fd852": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0c5976ac90c54b8ca68034802d633832",
              "IPY_MODEL_38b018b5205f4c23b8c223ba41ebd6eb",
              "IPY_MODEL_61201ab60bda48059162ef9815bf2aef"
            ],
            "layout": "IPY_MODEL_2201fa8b923c438996ed9aa94b272da9"
          }
        },
        "0c5976ac90c54b8ca68034802d633832": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_12d7982bd9de41549b2a1ec7fe1e8e1a",
            "placeholder": "​",
            "style": "IPY_MODEL_b33b93d57490490b8485ac4b12afcb03",
            "value": "config.json: 100%"
          }
        },
        "38b018b5205f4c23b8c223ba41ebd6eb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_da0a85d2f5d141d0af5b5ba0d0f20c53",
            "max": 2064,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f4fa9826fb9b4c138d2037a3ce36327e",
            "value": 2064
          }
        },
        "61201ab60bda48059162ef9815bf2aef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bb9aadf46c96415b90d31ad26020bce1",
            "placeholder": "​",
            "style": "IPY_MODEL_03e70543f8204b398783955e13cf0e77",
            "value": " 2.06k/2.06k [00:00&lt;00:00, 166kB/s]"
          }
        },
        "2201fa8b923c438996ed9aa94b272da9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "12d7982bd9de41549b2a1ec7fe1e8e1a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b33b93d57490490b8485ac4b12afcb03": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "da0a85d2f5d141d0af5b5ba0d0f20c53": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f4fa9826fb9b4c138d2037a3ce36327e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "bb9aadf46c96415b90d31ad26020bce1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "03e70543f8204b398783955e13cf0e77": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "825626df03644486af945e8764c5fda9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3cf7ae9822684589849fb2886e333227",
              "IPY_MODEL_3461a55edeb34b5c91bb306569cb1749",
              "IPY_MODEL_bae08a198ff842799930b4a1b13df99c"
            ],
            "layout": "IPY_MODEL_ee5bc22efbb84673aee5ec8492e29eb8"
          }
        },
        "3cf7ae9822684589849fb2886e333227": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_560848c05b974b09ab7636148cc8b525",
            "placeholder": "​",
            "style": "IPY_MODEL_42fdaf5c1e0b48acbedf00be7ca823e7",
            "value": "configuration_hf_nomic_bert.py: 100%"
          }
        },
        "3461a55edeb34b5c91bb306569cb1749": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a81aebbc02c648d69df281d4eaadeb38",
            "max": 1958,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_06556cfe6f1c404aac5a5484e0c873c6",
            "value": 1958
          }
        },
        "bae08a198ff842799930b4a1b13df99c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_37bea2c6d3864d4f881ec0cd530e40c1",
            "placeholder": "​",
            "style": "IPY_MODEL_17a4352dda1e45f6b6d7aa933312a72c",
            "value": " 1.96k/1.96k [00:00&lt;00:00, 165kB/s]"
          }
        },
        "ee5bc22efbb84673aee5ec8492e29eb8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "560848c05b974b09ab7636148cc8b525": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "42fdaf5c1e0b48acbedf00be7ca823e7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a81aebbc02c648d69df281d4eaadeb38": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "06556cfe6f1c404aac5a5484e0c873c6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "37bea2c6d3864d4f881ec0cd530e40c1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "17a4352dda1e45f6b6d7aa933312a72c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "49856f0ba9e84168a1ce6db84350e494": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9ed8cb6071af4f1c93187754168bf084",
              "IPY_MODEL_3a348823a00943d29dd8d0cc8d754510",
              "IPY_MODEL_44779322c1414b5da87a17925bdf4b8a"
            ],
            "layout": "IPY_MODEL_026b4ccdc0ea4412bf15991421c53eda"
          }
        },
        "9ed8cb6071af4f1c93187754168bf084": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_84618bcc47044468b48760e39f9989a0",
            "placeholder": "​",
            "style": "IPY_MODEL_700da68172fb4f0abf4295550bcff786",
            "value": "modeling_hf_nomic_bert.py: 100%"
          }
        },
        "3a348823a00943d29dd8d0cc8d754510": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_aec654c0c87f452f8776cc7cbdda9896",
            "max": 103563,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_298495a138d847de939b9d6704019a3b",
            "value": 103563
          }
        },
        "44779322c1414b5da87a17925bdf4b8a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_09487a1614b048a2bafacda4a6822aca",
            "placeholder": "​",
            "style": "IPY_MODEL_3786c23bf3a144f488e84d1d2ff0be2d",
            "value": " 104k/104k [00:00&lt;00:00, 7.84MB/s]"
          }
        },
        "026b4ccdc0ea4412bf15991421c53eda": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "84618bcc47044468b48760e39f9989a0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "700da68172fb4f0abf4295550bcff786": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "aec654c0c87f452f8776cc7cbdda9896": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "298495a138d847de939b9d6704019a3b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "09487a1614b048a2bafacda4a6822aca": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3786c23bf3a144f488e84d1d2ff0be2d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "37fe154b716a449fb36ffcd40370207d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_cc934572135b443380bfd6c53f355404",
              "IPY_MODEL_81c42550c5734a9eb89399e046b1d8e5",
              "IPY_MODEL_5f6cd961da72449cbda17bd4206d53bc"
            ],
            "layout": "IPY_MODEL_01f4b890b42246df8ed267ce021af2d3"
          }
        },
        "cc934572135b443380bfd6c53f355404": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_093b7802140b4fa39fe82f27c977f06c",
            "placeholder": "​",
            "style": "IPY_MODEL_0940a646cfca45deb2cc6726bf97178b",
            "value": "model.safetensors: 100%"
          }
        },
        "81c42550c5734a9eb89399e046b1d8e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2694714e016f478bbf85a764c44f785c",
            "max": 546938168,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f13c82e4ab924365b11f86d9bfab3d2d",
            "value": 546938168
          }
        },
        "5f6cd961da72449cbda17bd4206d53bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4044511a1906489b86157a8be5d8e5b3",
            "placeholder": "​",
            "style": "IPY_MODEL_eae3b55fcab14a8590780a27723415ac",
            "value": " 547M/547M [00:02&lt;00:00, 207MB/s]"
          }
        },
        "01f4b890b42246df8ed267ce021af2d3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "093b7802140b4fa39fe82f27c977f06c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0940a646cfca45deb2cc6726bf97178b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2694714e016f478bbf85a764c44f785c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f13c82e4ab924365b11f86d9bfab3d2d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4044511a1906489b86157a8be5d8e5b3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eae3b55fcab14a8590780a27723415ac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}